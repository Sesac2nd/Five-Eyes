from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import List, Optional
import uuid
import os
import dotenv
import re
import requests
import json
from datetime import datetime
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential
from models.chat import ChatMessage, HistoricalChatSession, HistoricalSearchLog
from config.database import get_db

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
dotenv.load_dotenv()

# Azure ì„¤ì •
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OAI_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OAI_ENDPOINT")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OAI_API_VER")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OAI_DEPLOY_NAME")
AZURE_OPENAI_MODEL_NAME1 = os.getenv("AZURE_OAI_MODEL_NAME1")  # ì°½ìž‘ë„ìš°ë¯¸ìš© ëª¨ë¸
AZURE_OPENAI_EMBEDDING = os.getenv("AZURE_OAI_EMBEDDING")

AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_KEY")

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = None
if AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT:
    client = AzureOpenAI(
        api_key=AZURE_OPENAI_API_KEY,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_version=AZURE_OPENAI_API_VERSION,
    )

# Azure Search í´ë¼ì´ì–¸íŠ¸
search_client = None
if AZURE_SEARCH_ENDPOINT and AZURE_SEARCH_INDEX_NAME and AZURE_SEARCH_API_KEY:
    search_client = SearchClient(
        endpoint=AZURE_SEARCH_ENDPOINT,
        index_name=AZURE_SEARCH_INDEX_NAME,
        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)
    )

SYSTEM_PROMPTS = {
    1: "ë²¡í„° ê²€ìƒ‰ëœ ì‚¬ë£Œì™€ ì¼ë°˜ì ì¸ ì—­ì‚¬ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìžìœ ë¡­ê²Œ ë‹µë³€í•´ì¤˜.",
    2: "ë²¡í„° ê²€ìƒ‰ëœ ì‚¬ë£Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, í•„ìš”ì‹œ ë§¥ë½ì„ ë³´íƒœ ì´ì•¼ê¸°ë¥¼ êµ¬ì„±í•´ì¤˜.",
    3: "ê²€ìƒ‰ëœ ì‚¬ë£Œë§Œ ì´ìš©í•˜ë©° ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì¤˜.",
    4: "ê²€ìƒ‰ëœ ì‚¬ë£Œì— ê¸°ë¡ëœ ë‚´ìš©ë§Œ í‘œí˜„í•˜ê³  ì›ë¬¸ ì¸ìš©ì´ ë°˜ë“œì‹œ ìžˆì–´ì•¼ í•´.",
    5: "ì‚¬ë£Œ ì›ë¬¸ë§Œ ì¸ìš©í•˜ê³  í•´ì„ì€ ê¸ˆì§€ì•¼. ì‚¬ë£Œì— ì—†ë‹¤ë©´ 'ì—†ìŒ'ìœ¼ë¡œ ë‹µí•´.",
}

# ì°½ìž‘ ì—„ê²©ë„ í”„ë¡¬í”„íŠ¸
CREATIVE_PROMPTS = {
    1: "ì™„ì „ížˆ ìžìœ ë¡œìš´ ì°½ìž‘ìœ¼ë¡œ, ì—­ì‚¬ì  ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë”ë¼ë„ í¥ë¯¸ë¡œìš´ ìŠ¤í† ë¦¬ë¥¼ ë§Œë“¤ì–´ì¤˜.",
    2: "ì—­ì‚¬ì  ë¶„ìœ„ê¸°ëŠ” ìœ ì§€í•˜ë˜, ì°½ì˜ì ì¸ í•´ì„ê³¼ ìƒìƒë ¥ì„ ë”í•´ì„œ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìž‘ì„±í•´ì¤˜.",
    3: "ì—­ì‚¬ì  ë°°ê²½ì€ ì •í™•ížˆ ìœ ì§€í•˜ë©´ì„œ, ì¸ë¬¼ê³¼ ì‚¬ê±´ì€ ì°½ìž‘ì ìœ¼ë¡œ êµ¬ì„±í•´ì¤˜.",
    4: "ì—­ì‚¬ì  ì‚¬ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, ê¸°ë¡ì— ì—†ëŠ” ë¶€ë¶„ë§Œ ìƒìƒë ¥ìœ¼ë¡œ ì±„ì›Œì„œ ìž‘ì„±í•´ì¤˜.",
    5: "ì² ì €ížˆ ì—­ì‚¬ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•´ì„œ, í™•ì¸ëœ ê¸°ë¡ ìœ„ì£¼ë¡œ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìž‘ì„±í•´ì¤˜.",
}

router = APIRouter()

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    strictness: Optional[int] = 3
    chat_mode: Optional[str] = "verification"  # verification ë˜ëŠ” creative

class ChatResponse(BaseModel):
    id: int
    session_id: str
    message: str
    response: str
    timestamp: str
    keywords: List[str]
    sources: List[str]
    strictness: int

class KeywordRequest(BaseModel):
    message: str

class KeywordResponse(BaseModel):
    keywords: List[str]

class ServiceStatus(BaseModel):
    status: str
    azure_openai_available: bool
    azure_search_available: bool
    creative_service_available: bool
    message: str



def extract_keywords(query: str) -> List[str]:
    """í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ - ë‘ ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼ ì ìš©"""
    if not client:
        return []
        
    try:
        prompt = f"""ë‹¤ìŒ ë¬¸ìž¥ì—ì„œ í•œêµ­ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë§Œ ì½¤ë§ˆë¡œ ì¶œë ¥:
{query}
í‚¤ì›Œë“œ:"""
        
        response = client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            max_tokens=50,
            temperature=0.2,
            messages=[
                {"role": "system", "content": "í‚¤ì›Œë“œë§Œ ì½¤ë§ˆë¡œ ì¶œë ¥"},
                {"role": "user", "content": prompt}
            ]
        )
        
        kw_line = response.choices[0].message.content.strip()
        keywords = [kw.strip() for kw in re.split(r'[,\n]', kw_line) if len(kw.strip()) > 0]
        return keywords[:5]  # ìµœëŒ€ 5ê°œë§Œ
        
    except Exception as e:
        print(f"[í‚¤ì›Œë“œ ì¶”ì¶œ ERROR] {e}")
        return []

def search_documents(keywords: List[str], top_k: int = 5) -> List[dict]:
    """ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜ - Azure Search ì§ì ‘ ì‚¬ìš©"""
    if not search_client:
        print("âŒ Azure Search í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    docs = []
    for kw in keywords:
        try:
            print(f"[ê²€ìƒ‰] í‚¤ì›Œë“œ: {kw}")
            results = search_client.search(kw, top=top_k, search_mode="any")
            
            for doc in results:
                # ë¬¸ì„œ í•„ë“œëª…ì€ ì‹¤ì œ ì¸ë±ìŠ¤ êµ¬ì¡°ì— ë§žê²Œ ì¡°ì • í•„ìš”
                chunk = doc.get('chunk', '') or doc.get('content', '') or doc.get('text', '')
                ref = doc.get('title', '') or doc.get('source', '') or doc.get('id', '')
                doc_id = doc.get('id', '') or doc.get('document_id', '')
                
                if chunk and len(chunk) > 50:
                    docs.append({
                        "keyword": kw, 
                        "content": chunk, 
                        "ref": ref,
                        "doc_id": doc_id
                    })
                    
        except Exception as e:
            print(f"[ê²€ìƒ‰ ì˜¤ë¥˜] í‚¤ì›Œë“œ '{kw}': {e}")
            continue
    
    # ì¤‘ë³µ ì œê±° (ë‚´ìš© ê¸°ì¤€)
    seen = set()
    unique_docs = []
    for d in docs:
        key = d['content'][:60]  # ì²˜ìŒ 60ìžë¡œ ì¤‘ë³µ íŒë‹¨
        if key not in seen:
            seen.add(key)
            unique_docs.append(d)
    
    print(f"[ê²€ìƒ‰ ì™„ë£Œ] ì´ {len(unique_docs)}ê°œ ë¬¸ì„œ ë°œê²¬")
    return unique_docs[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜

def create_verification_response(query: str, docs: List[dict], strictness: int = 3) -> tuple[str, List[str]]:
    """ê³ ì¦ ê²€ì¦ ëª¨ë“œ ì‘ë‹µ ìƒì„±: ëª¨ë“  ì—„ê²©ë„ì—ì„œ fallback í—ˆìš©"""
    if not client:
        return generate_simple_response(query), ["ê¸°ë³¸ ì‘ë‹µ ì‹œìŠ¤í…œ"]

    try:
        use_fallback = not docs
        context = "\n".join([f"[{d['ref']}] {d['content']}" for d in docs]) if docs else ""

        # âœ… fallback í”„ë¡¬í”„íŠ¸ (ì‚¬ë£Œ ì—†ìŒ ì‹œì—ë„ ì—„ê²©ë„ì— ë”°ë¼ í•©ë¦¬ì  ëŒ€ì‘)
        if use_fallback:
            fallback_prompts = {
                1: f"""ì§ˆë¬¸: {query}

ì‚¬ë£Œê°€ ì—†ì§€ë§Œ, í•œêµ­ì‚¬ ì§€ì‹ê³¼ ì—­ì‚¬ì  ë§¥ë½ì„ í™œìš©í•´ ìžìœ ë¡­ê³  ìœ ìµí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë‹µë³€:""",
                2: f"""ì§ˆë¬¸: {query}

ì‚¬ë£Œê°€ ì—†ì§€ë§Œ, ì—­ì‚¬ ì‚¬ì‹¤ê³¼ ë°°ê²½ì— ê·¼ê±°í•˜ì—¬ ì •í™•í•˜ê³  í’ë¶€í•œ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”.

ë‹µë³€:""",
                3: f"""ì§ˆë¬¸: {query}

ì‚¬ë£Œê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ì§€ë§Œ, ì•Œë ¤ì§„ ì—­ì‚¬ì  ì‚¬ì‹¤ê³¼ ê³µì  ë¬¸í—Œì— ê¸°ë°˜í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì¶œì²˜ëŠ” 'í•œêµ­ì‚¬ ì¼ë°˜ ì§€ì‹'ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

ë‹µë³€:""",
                4: f"""ì§ˆë¬¸: {query}

ì‚¬ë£ŒëŠ” ì—†ì§€ë§Œ, ê³µì‹ ë ¥ ìžˆëŠ” í•œêµ­ì‚¬ ìžë£Œì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ì§ì ‘ì  ì‚¬ì‹¤ë“¤ë§Œ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ '**ê¸°ë¡ ì—†ìŒ**', '**ë¶ˆí™•ì‹¤**'ë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš”.

ë‹µë³€:""",
                5: f"""ì§ˆë¬¸: {query}

ê²€ìƒ‰ëœ ì‚¬ë£ŒëŠ” ì—†ì§€ë§Œ, ì •ì‚¬(æ­£å²) ë˜ëŠ” ê³µì‹ ë ¥ ìžˆëŠ” ê³µì‹ ì—­ì‚¬ì„œì— ë“±ìž¥í•˜ëŠ” ì‚¬ì‹¤ë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì¶”ì¸¡, í•´ì„, ìƒìƒ ì—†ì´ ê¸°ë¡ëœ ë‚´ìš©ë§Œìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì—†ìœ¼ë©´ 'ê¸°ë¡ ì—†ìŒ'ì´ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€:"""
            }

            prompt = fallback_prompts.get(strictness, fallback_prompts[3])

            response = client.chat.completions.create(
                model=AZURE_OPENAI_DEPLOYMENT,
                max_tokens=800,
                temperature={1: 0.7, 2: 0.6, 3: 0.5, 4: 0.3, 5: 0.1}[strictness],
                messages=[
                    {"role": "system", "content": "í•œêµ­ì‚¬ ì „ë¬¸ê°€ë¡œì„œ ì •í™•í•˜ê³  ì‚¬ì‹¤ ì¤‘ì‹¬ì˜ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ]
            )

            answer = response.choices[0].message.content.strip()
            return answer, [f"í•œêµ­ì‚¬ ì¼ë°˜ ì§€ì‹ ì‘ë‹µ (ì‚¬ë£Œ ì—†ìŒ, ì—„ê²©ë„ {strictness})"]

        # âœ… ì‚¬ë£Œ ì¡´ìž¬ ì‹œ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        if strictness == 1:
            prompt = f"""ì§ˆë¬¸: {query}

ì•„ëž˜ ê²€ìƒ‰ëœ ì‚¬ë£Œì™€ ì¼ë°˜ì ì¸ í•œêµ­ì‚¬ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìžìœ ë¡­ê³  ìœ ìµí•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ë‹µë³€:"""
        elif strictness == 2:
            prompt = f"""ì§ˆë¬¸: {query}

ì•„ëž˜ ì‚¬ë£Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ í•˜ë˜, ë°°ê²½ ì§€ì‹ë„ ì ì ˆížˆ í™œìš©í•´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ë‹µë³€:"""
        elif strictness == 3:
            prompt = f"""ì§ˆë¬¸: {query}

ì•„ëž˜ ê²€ìƒ‰ëœ ì‚¬ë£Œë§Œì„ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ê³ , ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ ì‚¬ì‹¤ ìœ„ì£¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë§Œì•½ í•´ë‹¹ ì •ë³´ê°€ ì‚¬ë£Œì— ì—†ë‹¤ë©´ 'ì‚¬ë£Œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë¨¼ì € ëª…ì‹œí•œ í›„, 
ì¼ë°˜ì ì¸ ì—­ì‚¬ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…ì„ ì´ì–´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ë‹µë³€ (ì¶œì²˜ í¬í•¨):"""
        elif strictness == 4:
            prompt = f"""ì§ˆë¬¸: {query}

ì‚¬ë£Œì— ê´€ë ¨ëœ ì •ë³´ê°€ ìžˆë‹¤ë©´ ì›ë¬¸ì„ ëª…í™•ížˆ ì¸ìš©í•´ì£¼ì„¸ìš”.
ë§Œì•½ í•´ë‹¹ ì •ë³´ê°€ ì‚¬ë£Œì— ì—†ë‹¤ë©´ 'ì‚¬ë£Œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë¨¼ì € ëª…ì‹œí•œ í›„, 
ê³µì‹ ë ¥ ìžˆëŠ” ì—­ì‚¬ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…ì„ ì´ì–´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ë‹µë³€ (ì›ë¬¸ ì¸ìš© + ì¼ë°˜ ì§€ì‹ ë³´ì™„):"""
        else:  # strictness == 5
            prompt = f"""ì§ˆë¬¸: {query}

ì‚¬ë£Œ ì›ë¬¸ ì¤‘ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìžˆì„ ê²½ìš°ë§Œ ë¬¸ìž¥ì„ ê·¸ëŒ€ë¡œ ì¸ìš©í•´ì£¼ì„¸ìš”.
ë§Œì•½ í•´ë‹¹ ì •ë³´ê°€ ì‚¬ë£Œì— ì—†ë‹¤ë©´, 'ì‚¬ë£Œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ëª…ì‹œí•œ í›„
ì •ì‚¬(æ­£å²)ë‚˜ ê³µì‹ ë ¥ ìžˆëŠ” ì—­ì‚¬ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì¶”ì¸¡ì€ í”¼í•˜ê³ , ê¸°ë¡ëœ ê²ƒìœ¼ë¡œ ì•Œë ¤ì§„ ì‚¬ì‹¤ë§Œ ì „ë‹¬í•´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ì‘ë‹µ (ì‚¬ë£Œ ì¸ìš© â†’ ì¼ë°˜ ì§€ì‹ ë³´ì™„):"""


        response = client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            max_tokens=1000,
            temperature={1: 0.7, 2: 0.6, 3: 0.5, 4: 0.3, 5: 0.1}[strictness],
            messages=[
                {"role": "system", "content": "ì •í™•í•œ ì—­ì‚¬ì  ì‚¬ì‹¤ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì‚¬ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]
        )

        answer = response.choices[0].message.content.strip()
        sources = [d.get("ref") for d in docs if d.get("ref")] or [f"ê²€ìƒ‰ ì‚¬ë£Œ ì‚¬ìš© (ì—„ê²©ë„ {strictness})"]
        return answer, sources

    except Exception as e:
        print(f"[ê²€ì¦ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜] {e}")
        return f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", ["ì˜¤ë¥˜"]


def create_synopsis(query: str, keywords: List[str], docs: List[dict], strictness: int = 3) -> tuple[str, List[str]]:
    """ì°½ìž‘ë„ìš°ë¯¸ìš© ì‹œë†‰ì‹œìŠ¤ ìƒì„± - ë‘ ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼ ì ìš©"""
    if not client:
        return "âŒ ì°½ìž‘ ë„ìš°ë¯¸ ëª¨ë¸ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.", []
        
    try:
        context = "\n".join([d['content'] for d in docs]) if docs else ""
        creative_prompt = CREATIVE_PROMPTS.get(strictness, CREATIVE_PROMPTS[3])
        
        # ì‚¬ë£Œê°€ ì—†ì„ ë•Œë„ ì°½ìž‘ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •
        if docs:
            synopsis_prompt = f"""ì§ˆë¬¸: {query}
í‚¤ì›Œë“œ: {', '.join(keywords)}

ì•„ëž˜ ì‚¬ë£Œë¥¼ ì°¸ê³ í•˜ì—¬ 500ìž ì´ë‚´ë¡œ ë“œë¼ë§ˆí‹±í•œ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”.

ì‚¬ë£Œ:
{context}

ì°½ìž‘ ì§€ì¹¨: {creative_prompt}

ì‹œë†‰ì‹œìŠ¤:"""
        else:
            synopsis_prompt = f"""ì§ˆë¬¸: {query}
í‚¤ì›Œë“œ: {', '.join(keywords)}

ì‚¬ë£ŒëŠ” ì—†ì§€ë§Œ í•œêµ­ì‚¬ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ 500ìž ì´ë‚´ì˜ ë“œë¼ë§ˆí‹±í•œ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”.

ì°½ìž‘ ì§€ì¹¨: {creative_prompt}

ì‹œë†‰ì‹œìŠ¤:"""
        
        model = AZURE_OPENAI_MODEL_NAME1 if AZURE_OPENAI_MODEL_NAME1 else AZURE_OPENAI_DEPLOYMENT
        
        response = client.chat.completions.create(
            model=model,
            max_tokens=1000,
            temperature={1: 1.0, 2: 0.9, 3: 0.8, 4: 0.6, 5: 0.4}.get(strictness, 0.8),
            messages=[
                {"role": "system", "content": "í•œêµ­ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°½ì˜ì ì´ê³  í¥ë¯¸ì§„ì§„í•œ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": synopsis_prompt}
            ]
        )
        
        text = response.choices[0].message.content.strip()
        
        # ì¶œì²˜ ì •ë³´ ìƒì„±
        sources = []
        if docs:
            for doc in docs:
                if doc.get('ref'):
                    sources.append(f"ã€Ž{doc['ref']}ã€")
        
        if not sources:
            sources = ["í•œêµ­ì‚¬ ì§€ì‹ ê¸°ë°˜ ì°½ìž‘"]
            
        return text, sources
        
    except Exception as e:
        print(f"[ì‹œë†‰ì‹œìŠ¤ ìƒì„± ERROR] {e}")
        return f"âŒ ì‹œë†‰ì‹œìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}", []

def factual_similarity(synopsis: str, ground_truth: str = "") -> str:
    """ì‚¬ì‹¤ì„± í‰ê°€ í•¨ìˆ˜"""
    if not client or not ground_truth:
        return "í‰ê°€ ë°ì´í„°ê°€ ì—†ì–´ ì‚¬ì‹¤ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        prompt = f"""í•™ìƒì´ ì“´ ìš”ì•½: {synopsis}
ìˆ˜ëŠ¥íŠ¹ê°• ì„¤ëª… ì›ë¬¸: {ground_truth}
ë‘ ë‚´ìš©ì˜ ì‚¬ì‹¤ì  ì¼ì¹˜ë„(íŒ©íŠ¸, ì‹œëŒ€/ì£¼ì œ ë¶€í•© ë“±)ë¥¼ 5ì  ë§Œì ìœ¼ë¡œ ìˆ˜ì¹˜ì™€ ì„¤ëª…ìœ¼ë¡œ í‰ê°€í•´ì¤˜."""

        response = client.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            max_tokens=500,
            temperature=0.7,
            messages=[
                {"role": "system", "content": "ì‚¬ì‹¤ì„± í‰ê°€ ì „ë¬¸ê°€"},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"[ì‚¬ì‹¤ì„± í‰ê°€ ì˜¤ë¥˜] {e}")
        return f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def generate_simple_response(message: str) -> str:
    """ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±ê¸° (AI ì„œë¹„ìŠ¤ ì—†ì„ ë•Œ ì‚¬ìš©)"""
    if "ì•ˆë…•" in message:
        return "ì•ˆë…•í•˜ì„¸ìš”! ì¡°ì„ ì™•ì¡°ì‹¤ë¡ ê¸°ë°˜ ì—­ì‚¬ AIìž…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    elif "ì„¸ì¢…" in message:
        return "ì„¸ì¢…ëŒ€ì™•(ìž¬ìœ„ 1418-1450)ì€ ì¡°ì„ ì˜ 4ëŒ€ ì™•ìœ¼ë¡œ, í•œê¸€ ì°½ì œì™€ ë‹¤ì–‘í•œ ë¬¸í™” ì •ì±…ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤."
    elif "ìž„ì§„ì™œëž€" in message:
        return "ìž„ì§„ì™œëž€(1592-1598)ì€ ì¡°ì„  ì„ ì¡° ì‹œê¸°ì— ì¼ë³¸ì´ ì¡°ì„ ì„ ì¹¨ìž…í•œ ì „ìŸìž…ë‹ˆë‹¤."
    else:
        return f"'{message}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¡°ì„ ì™•ì¡°ì‹¤ë¡ì—ì„œ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."

def debug_azure_search():
    """Azure Search ì—°ê²° ë° ë°ì´í„° í™•ì¸"""
    if not search_client:
        print("âŒ Azure Search í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ì§ì ‘ ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
        results = search_client.search("ì„¸ì¢…", top=3)
        doc_count = 0
        for result in results:
            doc_count += 1
            print(f"ðŸ“„ ë¬¸ì„œ {doc_count}: {list(result.keys())}")
        
        if doc_count > 0:
            print(f"âœ… Azure Search ì •ìƒ ìž‘ë™ - {doc_count}ê°œ ë¬¸ì„œ ë°œê²¬")
            return True
        else:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"âŒ Azure Search ì—°ê²° ì˜¤ë¥˜: {e}")
        return False

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@router.post("/chat", response_model=ChatResponse)
async def historical_chat(request: ChatRequest, db: Session = Depends(get_db)):
    session_id = request.session_id or str(uuid.uuid4())
    created_at = datetime.utcnow().isoformat()

    strictness = request.strictness or 3
    if strictness not in range(1, 6):
        raise HTTPException(status_code=400, detail="ì—„ê²©ë„ëŠ” 1~5 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    chat_mode = request.chat_mode or "verification"
    keywords = []
    sources = []

    try:
        # ì‚¬ìš©ìž ë©”ì‹œì§€ ì €ìž¥
        user_message = ChatMessage(
            session_id=session_id,
            message_type="user",
            content=request.message,
            audio_requested=False
        )
        db.add(user_message)
        db.flush()

        print("\n" + "=" * 50)
        print("â¶ [ì§ˆë¬¸ì—ì„œ ë½‘ì•„ë‚¸ í‚¤ì›Œë“œ]")
        
        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords(request.message)
        print(keywords)
        
        # 2. ë¬¸ì„œ ê²€ìƒ‰
        docs = search_documents(keywords, top_k=5)
        
        if chat_mode == "creative":
            # ì°½ìž‘ë„ìš°ë¯¸ ëª¨ë“œ
            print("\nâ· [ë‹µë³€ ì‹œë†‰ì‹œìŠ¤]")
            synopsis, sources = create_synopsis(request.message, keywords, docs, strictness)
            answer = synopsis
            print(synopsis)
            
        else:
            # ê³ ì¦ ê²€ì¦ ëª¨ë“œ
            print("\nâ· [ë‹µë³€ ë‚´ìš©]")
            answer, sources = create_verification_response(request.message, docs, strictness)
            print(answer)
        
        print("\nâ¸ [ë‹µë³€ì— í™œìš©í•œ ì‚¬ë£Œ ì¶œì²˜]")
        if sources:
            for source in sources:
                print(f"- {source}")
        else:
            print("- ì¶œì²˜ ì •ë³´ ì—†ìŒ")

        # ë´‡ ì‘ë‹µ ì €ìž¥
        bot_message = ChatMessage(
            session_id=session_id,
            message_type="historical_bot" if chat_mode == "verification" else "creative_bot",
            content=answer,
            audio_requested=False
        )
        db.add(bot_message)
        db.commit()

        return ChatResponse(
            id=user_message.id,
            session_id=session_id,
            message=request.message,
            response=answer,
            timestamp=created_at,
            keywords=keywords or ["í‚¤ì›Œë“œ ì—†ìŒ"],
            sources=sources or ["ì¶œì²˜ ì •ë³´ ì—†ìŒ"],
            strictness=strictness,
        )
        
    except Exception as e:
        print(f"[ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜] {e}")
        import traceback
        print(traceback.format_exc())
        db.rollback()
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì˜¤ë¥˜: {str(e)}")

@router.post("/extract-keywords", response_model=KeywordResponse)
async def extract_keywords_endpoint(request: KeywordRequest):
    try:
        keywords = extract_keywords(request.message)
        return KeywordResponse(keywords=keywords)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")

@router.get("/chat/status", response_model=ServiceStatus)
async def get_service_status():
    try:
        openai_ok = bool(AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_DEPLOYMENT)
        search_ok = bool(search_client is not None)
        creative_ok = bool(AZURE_OPENAI_MODEL_NAME1)

        return ServiceStatus(
            status="healthy" if openai_ok and search_ok else "partial",
            azure_openai_available=openai_ok,
            azure_search_available=search_ok,
            creative_service_available=creative_ok,
            message="ëª¨ë“  ì„¤ì •ì´ ì •ìƒìž…ë‹ˆë‹¤." if openai_ok and search_ok and creative_ok else "ì¼ë¶€ ì„¤ì • ëˆ„ë½ í™•ì¸ í•„ìš”"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@router.get("/chat/strictness-info")
async def get_strictness_info():
    return {
        "verification_strictness": {
            1: {"name": "ê´€ëŒ€", "description": "ì¶”ë¡  ê°€ëŠ¥, ì—­ì‚¬ ì§€ì‹ í™œìš©", "color": "#10b981"},
            2: {"name": "ë³´í†µ-ê´€ëŒ€", "description": "ì‚¬ë£Œ + ì—­ì‚¬ ë§¥ë½", "color": "#3b82f6"},
            3: {"name": "ë³´í†µ", "description": "ì‚¬ë£Œ ì¤‘ì‹¬, ì¶œì²˜ ëª…ì‹œ", "color": "#6b7280"},
            4: {"name": "ë³´í†µ-ì—„ê²©", "description": "ì‚¬ë£Œ ì›ë¬¸ ìœ„ì£¼, ë¶€ì—° ì—†ìŒ", "color": "#f59e0b"},
            5: {"name": "ì—„ê²©", "description": "ì‚¬ë£Œ ì›ë¬¸ ì™¸ ë‚´ìš© ì™„ì „ ê¸ˆì§€", "color": "#ef4444"},
        },
        "creative_strictness": {
            1: {"name": "ìžìœ ", "description": "ì™„ì „ ìžìœ  ì°½ìž‘, ì—­ì‚¬ ë¬´ì‹œ ê°€ëŠ¥", "color": "#10b981"},
            2: {"name": "ë³´í†µ-ìžìœ ", "description": "ì—­ì‚¬ì  ë¶„ìœ„ê¸° + ì°½ì˜ì  í•´ì„", "color": "#3b82f6"},
            3: {"name": "ë³´í†µ", "description": "ì—­ì‚¬ì  ë°°ê²½ ìœ ì§€ + ì°½ìž‘ì  êµ¬ì„±", "color": "#6b7280"},
            4: {"name": "ë³´í†µ-ì œí•œ", "description": "ì—­ì‚¬ì  ì‚¬ì‹¤ ê¸°ë°˜ + ë¶€ë¶„ ìƒìƒ", "color": "#f59e0b"},
            5: {"name": "ì œí•œ", "description": "ì² ì €í•œ ì—­ì‚¬ì  ì‚¬ì‹¤ ê¸°ë°˜", "color": "#ef4444"},
        }
    }

# ë””ë²„ê¹… ì—”ë“œí¬ì¸íŠ¸ë“¤
@router.get("/debug/env")
async def debug_environment():
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì • ìƒíƒœ í™•ì¸"""
    env_status = {
        "azure_openai": {
            "api_key": "ì„¤ì •ë¨" if AZURE_OPENAI_API_KEY else "âŒ ì—†ìŒ",
            "endpoint": AZURE_OPENAI_ENDPOINT or "âŒ ì—†ìŒ", 
            "api_version": AZURE_OPENAI_API_VERSION or "âŒ ì—†ìŒ",
            "deployment": AZURE_OPENAI_DEPLOYMENT or "âŒ ì—†ìŒ",
            "model_name1": AZURE_OPENAI_MODEL_NAME1 or "âŒ ì—†ìŒ",
            "embedding": AZURE_OPENAI_EMBEDDING or "âŒ ì—†ìŒ"
        },
        "azure_search": {
            "endpoint": AZURE_SEARCH_ENDPOINT or "âŒ ì—†ìŒ",
            "index_name": AZURE_SEARCH_INDEX_NAME or "âŒ ì—†ìŒ", 
            "api_key": "ì„¤ì •ë¨" if AZURE_SEARCH_API_KEY else "âŒ ì—†ìŒ"
        },
        "clients": {
            "openai_initialized": client is not None,
            "search_initialized": search_client is not None
        }
    }
    
    return env_status

@router.get("/debug/azure-search")
async def debug_azure_search_endpoint():
    """Azure Search ìƒíƒœ ë””ë²„ê¹…"""
    try:
        is_working = debug_azure_search()
        return {
            "azure_search_working": is_working,
            "endpoint": AZURE_SEARCH_ENDPOINT,
            "index_name": AZURE_SEARCH_INDEX_NAME,
            "api_key_set": bool(AZURE_SEARCH_API_KEY),
            "client_initialized": search_client is not None
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë””ë²„ê¹… ì‹¤íŒ¨: {str(e)}")

@router.get("/debug/test-search")
async def test_search_endpoint():
    """ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    try:
        test_keywords = ["ì„¸ì¢…ëŒ€ì™•", "ì¡°ì„ ", "í•œê¸€"]
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        extracted_keywords = extract_keywords("ì„¸ì¢…ëŒ€ì™•ì˜ í•œê¸€ ì°½ì œì— ëŒ€í•´ ì•Œë ¤ì¤˜")
        
        # ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        docs = search_documents(test_keywords, top_k=3)
        
        return {
            "test_keywords": test_keywords,
            "extracted_keywords": extracted_keywords,
            "search_results_count": len(docs),
            "search_results": [
                {
                    "keyword": doc.get("keyword", ""),
                    "content_preview": doc.get("content", "")[:100] + "..." if len(doc.get("content", "")) > 100 else doc.get("content", ""),
                    "ref": doc.get("ref", ""),
                    "doc_id": doc.get("doc_id", "")
                }
                for doc in docs
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")