from fastapi import FastAPI, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional
import os
from dotenv import load_dotenv
import base64
from datetime import datetime
import logging
import traceback

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
if not logging.getLogger().handlers:
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="TTS API Only",
    version="1.0.0",
    description="Azure Speech ê¸°ë°˜ TTS ì „ìš© API ì„œë²„",
)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------- Pydantic Models -------------------


class TTSRequest(BaseModel):
    text: str
    voice_name: Optional[str] = "ko-KR-HyunsuMultilingualNeural"


class TTSResponse(BaseModel):
    success: bool
    audio_data: Optional[str] = None
    error: Optional[str] = None
    voice_name: str
    text: str


# ------------------- Azure TTS Function -------------------


async def azure_text_to_speech(text: str, voice_name: str) -> TTSResponse:
    try:
        import azure.cognitiveservices.speech as speechsdk

        speech_key = os.getenv("AZURE_SPEECH_KEY")
        speech_region = os.getenv("AZURE_SPEECH_REGION", "koreacentral")

        if not speech_key:
            logger.error("Azure Speech Keyê°€ ì—†ìŒ")
            return TTSResponse(
                success=False,
                error="Azure Speech Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                voice_name=voice_name,
                text=text,
            )

        speech_config = speechsdk.SpeechConfig(
            subscription=speech_key, region=speech_region
        )
        speech_config.speech_synthesis_voice_name = voice_name

        # ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì‹œë„ (ê¶Œì¥)
        pull_stream = speechsdk.audio.PullAudioOutputStream()
        audio_config = speechsdk.audio.AudioOutputConfig(stream=pull_stream)
        synthesizer = speechsdk.SpeechSynthesizer(
            speech_config=speech_config, audio_config=audio_config
        )

        logger.info(f"[TTS] ìš”ì²­: '{text}' (voice: {voice_name})")
        result = synthesizer.speak_text_async(text.strip()).get()

        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            audio_data = result.audio_data
            if audio_data and len(audio_data) > 0:
                audio_base64 = base64.b64encode(audio_data).decode("utf-8")
                return TTSResponse(
                    success=True,
                    audio_data=audio_base64,
                    voice_name=voice_name,
                    text=text,
                )
            else:
                raise Exception("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")

        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation_details = result.cancellation_details
            error_msg = f"TTS ì·¨ì†Œ: {cancellation_details.reason} - {cancellation_details.error_details or ''}"
            logger.error(error_msg)
            raise Exception(error_msg)

        else:
            logger.error(f"TTS ì‹¤íŒ¨: {result.reason}")
            raise Exception(f"TTS ì‹¤íŒ¨: {result.reason}")

    except ImportError:
        return TTSResponse(
            success=False,
            error="Azure Speech SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            voice_name=voice_name,
            text=text,
        )
    except Exception as e:
        logger.error(f"TTS ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        return TTSResponse(
            success=False, error=str(e), voice_name=voice_name, text=text
        )


# ------------------- API Endpoints -------------------


@app.post("/api/tts", response_model=TTSResponse)
async def text_to_speech_form(
    text: str = Form(...), voice_name: str = Form("ko-KR-HyunsuMultilingualNeural")
):
    """í…ìŠ¤íŠ¸ë¥¼ Azure TTSë¡œ ë³€í™˜(Form ë°©ì‹)"""
    if not text or len(text.strip()) == 0:
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    if len(text) > 1000:
        raise HTTPException(
            status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤(1000ì ì œí•œ)."
        )
    return await azure_text_to_speech(text, voice_name)


@app.post("/api/tts-json", response_model=TTSResponse)
async def text_to_speech_json(request: TTSRequest):
    """í…ìŠ¤íŠ¸ë¥¼ Azure TTSë¡œ ë³€í™˜(JSON ë°©ì‹)"""
    if not request.text or len(request.text.strip()) == 0:
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    if len(request.text) > 1000:
        raise HTTPException(
            status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤(1000ì ì œí•œ)."
        )
    return await azure_text_to_speech(
        request.text, request.voice_name or "ko-KR-HyunsuMultilingualNeural"
    )


@app.get("/api/voices")
async def get_available_voices():
    """Azure í•œêµ­ì–´ ìŒì„± ëª©ë¡ ë° ê¸°ë³¸ê°’ ì œê³µ"""
    return {
        "korean_voices": [
            {
                "name": "ko-KR-HyunsuMultilingualNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„±(ë‹¤êµ­ì–´ ê°€ëŠ¥)",
            },
            {
                "name": "ko-KR-SunHiNeural",
                "gender": "Female",
                "description": "í•œêµ­ì–´ ì—¬ì„±",
            },
            {
                "name": "ko-KR-InJoonNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„±",
            },
            {
                "name": "ko-KR-BongJinNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„±",
            },
            {
                "name": "ko-KR-GookMinNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„±",
            },
        ],
        "default": "ko-KR-HyunsuMultilingualNeural",
    }


@app.post("/api/navigation-tts", response_model=TTSResponse)
async def navigation_tts(request: TTSRequest):
    """ë„¤ë¹„ê²Œì´ì…˜ ì•ˆë‚´ìŒ ì¤‘ì‹¬ TTS(API ë‹¨ìˆœí™”)"""
    # 200ì ì´ˆê³¼ëŠ” ìë™ ì¤„ì´ê¸°
    text = request.text[:200] + "..." if len(request.text) > 200 else request.text
    common_phrases = {
        "ëª©ì ì§€ í™•ì¸": "ëª©ì ì§€ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê² ìŠµë‹ˆë‹¤.",
        "ê²½ë¡œ íƒìƒ‰": "ê²½ë¡œë¥¼ íƒìƒ‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.",
        "ì•ˆë‚´ ì‹œì‘": "ì•ˆë‚´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.",
        "ì§ì§„": "ì§ì§„í•˜ì„¸ìš”.",
        "ìš°íšŒì „": "ìš°íšŒì „í•˜ì„¸ìš”.",
        "ì¢ŒíšŒì „": "ì¢ŒíšŒì „í•˜ì„¸ìš”.",
        "ë„ì°©": "ëª©ì ì§€ì— ë„ì°©í–ˆìŠµë‹ˆë‹¤.",
    }
    for key, phrase in common_phrases.items():
        if key in text or phrase in text:
            text = phrase
            break
    return await azure_text_to_speech(
        text, request.voice_name or "ko-KR-HyunsuMultilingualNeural"
    )


@app.get("/test/voice")
async def test_voice_service():
    """TTS ì„œë¹„ìŠ¤ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    test_text = "ì•ˆë…•í•˜ì„¸ìš”. Azure ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
    test_request = TTSRequest(
        text=test_text, voice_name="ko-KR-HyunsuMultilingualNeural"
    )
    result = await azure_text_to_speech(test_text, test_request.voice_name)
    audio_size = len(base64.b64decode(result.audio_data)) if result.audio_data else 0
    return {
        "success": result.success,
        "message": "ì„œë¹„ìŠ¤ ì •ìƒ" if result.success else "ìŒì„± ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨",
        "audio_size": audio_size,
        "test_text": test_text,
        "error": result.error if not result.success else None,
    }


# ì‹¬í”Œ ìƒíƒœ í™•ì¸
@app.get("/")
async def root():
    return {
        "message": "Azure Speech TTS ì „ìš© API",
        "version": "1.0.0",
        "time": datetime.now().isoformat(),
        "endpoints": [
            "/api/tts",
            "/api/tts-json",
            "/api/voices",
            "/api/navigation-tts",
            "/test/voice",
        ],
    }


if __name__ == "__main__":
    import uvicorn

    logger.info("ğŸš€ Azure Speech TTS API ì„œë²„ ì‹œì‘ (í¬íŠ¸: 8000)")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
