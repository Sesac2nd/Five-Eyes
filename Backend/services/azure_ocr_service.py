# services/azure_ocr_service.py
import os
import time
import logging
import numpy as np
from typing import List, Dict, Optional
from dotenv import load_dotenv
from utils.image_processing import ImageProcessor
from utils.text_processing import HistoricalDocumentTextProcessor
from models.ocr import WordResult, LineResult

load_dotenv()
logger = logging.getLogger(__name__)


class AzureOCRService:
    """Azure Document Intelligence OCR ÏÑúÎπÑÏä§ - Î≤îÏö©"""

    def __init__(self):
        self.client = None
        self.enabled = False
        self._initialize_azure_client()

    def _initialize_azure_client(self):
        """Azure Document Intelligence ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî"""
        try:
            # Azure SDK ÏûÑÌè¨Ìä∏ (ÏßÄÏó∞ Î°úÎî©)
            from azure.core.credentials import AzureKeyCredential
            from azure.ai.documentintelligence import DocumentIntelligenceClient
            from azure.ai.documentintelligence.models import AnalyzeDocumentRequest

            # ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú ÏÑ§Ï†ï ÏùΩÍ∏∞
            endpoint = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
            key = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_KEY")

            if not endpoint or not key:
                logger.error(
                    "‚ùå Azure Document Intelligence ÌôòÍ≤ΩÎ≥ÄÏàòÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§."
                )
                logger.info("ÌïÑÏöîÌïú ÌôòÍ≤ΩÎ≥ÄÏàò:")
                logger.info("- AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
                logger.info("- AZURE_DOCUMENT_INTELLIGENCE_KEY")
                self.enabled = False
                return

            # ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ±
            self.client = DocumentIntelligenceClient(
                endpoint=endpoint, credential=AzureKeyCredential(key)
            )

            # Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ (Í∞ÑÎã®Ìïú ÏöîÏ≤≠ÏúºÎ°ú)
            logger.info("üîó Azure Document Intelligence Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ Ï§ë...")
            # Ïã§Ï†ú Ïó∞Í≤∞ ÌÖåÏä§Ìä∏Îäî Ï≤´ ÏöîÏ≤≠ Ïãú ÌôïÏù∏

            self.enabled = True
            logger.info("‚úÖ Azure Document Intelligence Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ")
            logger.info(f"Endpoint: {endpoint}")

        except ImportError as e:
            logger.error(f"Azure SDKÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏùå: {e}")
            logger.info("ÏÑ§Ïπò Î™ÖÎ†πÏñ¥: pip install azure-ai-documentintelligence")
            self.enabled = False
        except Exception as e:
            logger.error(f"Azure Document Intelligence Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.enabled = False

    def is_available(self) -> bool:
        """ÏÑúÎπÑÏä§ ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä"""
        return self.enabled and self.client is not None

    def process_image(self, image_data: bytes) -> Dict:
        """Ïù¥ÎØ∏ÏßÄ OCR Ï≤òÎ¶¨ Î©îÏù∏ Ìï®Ïàò"""
        if not self.is_available():
            return {
                "success": False,
                "error": "Azure Document Intelligence ÏÑúÎπÑÏä§Í∞Ä ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ ÏûàÏäµÎãàÎã§.",
                "processing_time": 0.0,
            }

        start_time = time.time()

        try:
            # Azure SDK ÏûÑÌè¨Ìä∏ (Ìï®Ïàò ÎÇ¥Î∂ÄÏóêÏÑú)
            from azure.ai.documentintelligence.models import AnalyzeDocumentRequest

            # 1. Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
            logger.info("üîÑ AzureÏö© Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë")
            processed_image = ImageProcessor.enhance_image_for_ocr(image_data, "azure")

            # 2. Azure Document Intelligence API Ìò∏Ï∂ú
            logger.info("üì° Azure Document Intelligence API Ìò∏Ï∂ú Ï§ë...")

            analyze_request = AnalyzeDocumentRequest(bytes_source=processed_image)

            # ÎπÑÎèôÍ∏∞ Î∂ÑÏÑù ÏãúÏûë
            poller = self.client.begin_analyze_document(
                model_id="prebuilt-read",  # ÏùºÎ∞ò ÌÖçÏä§Ìä∏ ÏùΩÍ∏∞ Î™®Îç∏
                analyze_request=analyze_request,
            )

            # Í≤∞Í≥º ÎåÄÍ∏∞
            logger.info("‚è≥ Azure Î∂ÑÏÑù ÏôÑÎ£å ÎåÄÍ∏∞ Ï§ë...")
            result = poller.result()

            # 3. Í≤∞Í≥º Ï≤òÎ¶¨
            processed_result = self._process_azure_result(result)

            processing_time = time.time() - start_time
            logger.info(f"‚úÖ Azure OCR Ï≤òÎ¶¨ ÏôÑÎ£å ({processing_time:.2f}Ï¥à)")

            return {
                "success": True,
                "processing_time": processing_time,
                **processed_result,
            }

        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"‚ùå Azure OCR Ï≤òÎ¶¨ Ïã§Ìå®: {e}")

            # ÏóêÎü¨ ÌÉÄÏûÖÎ≥Ñ ÏÉÅÏÑ∏ Î©îÏãúÏßÄ
            error_message = str(e)
            if "401" in error_message or "Unauthorized" in error_message:
                error_message = "Azure API ÌÇ§Í∞Ä Ïú†Ìö®ÌïòÏßÄ ÏïäÏäµÎãàÎã§."
            elif "403" in error_message or "Forbidden" in error_message:
                error_message = (
                    "Azure API Ï†ëÍ∑ºÏù¥ Í±∞Î∂ÄÎêòÏóàÏäµÎãàÎã§. Íµ¨ÎèÖ ÏÉÅÌÉúÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî."
                )
            elif "429" in error_message or "rate limit" in error_message.lower():
                error_message = "Azure API ÏöîÏ≤≠ ÌïúÎèÑÎ•º Ï¥àÍ≥ºÌñàÏäµÎãàÎã§."
            elif "timeout" in error_message.lower():
                error_message = "Azure API ÏöîÏ≤≠ ÏãúÍ∞ÑÏù¥ Ï¥àÍ≥ºÎêòÏóàÏäµÎãàÎã§."

            return {
                "success": False,
                "error": f"Azure OCR Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {error_message}",
                "processing_time": processing_time,
            }

    def _process_azure_result(self, azure_result) -> Dict:
        """Azure Í≤∞Í≥ºÎ•º ÌÜµÏùºÎêú ÌòïÌÉúÎ°ú Î≥ÄÌôò"""
        if (
            not azure_result
            or not hasattr(azure_result, "pages")
            or not azure_result.pages
        ):
            return {
                "lines": [],
                "full_text": "",
                "word_count": 0,
                "confidence_avg": 0.0,
            }

        try:
            # Azure Í≤∞Í≥ºÏóêÏÑú Îã®Ïñ¥ Ï†ïÎ≥¥ Ï∂îÏ∂ú
            words_data = []

            for page in azure_result.pages:
                if hasattr(page, "words") and page.words:
                    for word in page.words:
                        # Azure Í≤∞Í≥º Íµ¨Ï°∞
                        text = word.content if hasattr(word, "content") else ""
                        confidence = (
                            word.confidence if hasattr(word, "confidence") else 1.0
                        )

                        # polygon Ï†ïÎ≥¥ Ï∂îÏ∂ú
                        polygon = []
                        if hasattr(word, "polygon") and word.polygon:
                            polygon = list(word.polygon)

                        # bbox Í≥ÑÏÇ∞
                        if polygon and len(polygon) >= 8:
                            x_coords = [polygon[i] for i in range(0, len(polygon), 2)]
                            y_coords = [polygon[i] for i in range(1, len(polygon), 2)]

                            min_x = min(x_coords)
                            max_x = max(x_coords)
                            min_y = min(y_coords)
                            max_y = max(y_coords)

                            bbox = [
                                int(min_x),
                                int(min_y),
                                int(max_x - min_x),
                                int(max_y - min_y),
                            ]
                            center_x = (min_x + max_x) / 2
                            center_y = (min_y + max_y) / 2
                        else:
                            # polygonÏù¥ ÏóÜÎäî Í≤ΩÏö∞ Í∏∞Î≥∏Í∞í
                            bbox = [0, 0, 100, 20]
                            center_x = 50
                            center_y = 10

                        words_data.append(
                            {
                                "text": text,
                                "confidence": float(confidence),
                                "polygon": polygon,
                                "bbox": bbox,
                                "center_x": center_x,
                                "center_y": center_y,
                            }
                        )

            if not words_data:
                return {
                    "lines": [],
                    "full_text": "",
                    "word_count": 0,
                    "confidence_avg": 0.0,
                }

            # Ïó≠ÏÇ¨Î¨∏ÏÑú ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨Í∏∞Î°ú Ï†ïÎ†¨
            processor = HistoricalDocumentTextProcessor()
            vertical_lines = processor.group_words_by_lines(words_data)

            # LineResult Í∞ùÏ≤¥Îì§ ÏÉùÏÑ±
            lines = []
            all_confidences = []
            full_text_parts = []

            for line_idx, line_words in enumerate(vertical_lines):
                # ÎùºÏù∏Î≥Ñ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
                line_confidences = [w["confidence"] for w in line_words]
                line_texts = [w["text"] for w in line_words]

                # ÎùºÏù∏ Î∞îÏö¥Îî© Î∞ïÏä§ Í≥ÑÏÇ∞
                if line_words:
                    all_bboxes = [w["bbox"] for w in line_words]
                    min_x = min(bbox[0] for bbox in all_bboxes)
                    min_y = min(bbox[1] for bbox in all_bboxes)
                    max_x = max(bbox[0] + bbox[2] for bbox in all_bboxes)
                    max_y = max(bbox[1] + bbox[3] for bbox in all_bboxes)
                    line_bbox = [min_x, min_y, max_x - min_x, max_y - min_y]
                else:
                    line_bbox = [0, 0, 0, 0]

                # WordResult Í∞ùÏ≤¥Îì§ ÏÉùÏÑ±
                word_results = []
                for word in line_words:
                    word_result = WordResult(
                        text=word["text"],
                        confidence=word["confidence"],
                        bbox=word["bbox"],
                        polygon=word["polygon"] if word["polygon"] else None,
                    )
                    word_results.append(word_result)

                # LineResult ÏÉùÏÑ±
                line_result = LineResult(
                    line_number=line_idx + 1,
                    words=word_results,
                    full_text="".join(line_texts),
                    avg_confidence=(
                        np.mean(line_confidences) if line_confidences else 0.0
                    ),
                    bbox=line_bbox,
                )

                lines.append(line_result)
                all_confidences.extend(line_confidences)
                full_text_parts.extend(line_texts)

            return {
                "lines": lines,
                "full_text": "".join(full_text_parts),
                "word_count": len(words_data),
                "confidence_avg": np.mean(all_confidences) if all_confidences else 0.0,
            }

        except Exception as e:
            logger.error(f"Azure OCR Í≤∞Í≥º Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
            return {
                "lines": [],
                "full_text": "",
                "word_count": 0,
                "confidence_avg": 0.0,
            }


# Ï†ÑÏó≠ Ïù∏Ïä§ÌÑ¥Ïä§
azure_ocr_service = AzureOCRService()
