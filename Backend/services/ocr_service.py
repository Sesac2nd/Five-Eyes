import os
import json
import time
from typing import Dict, Optional, Any
from dotenv import load_dotenv
import traceback

load_dotenv()
DEBUG_FLAG = os.getenv("IS_DEBUG", "")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ ì„¤ì • (Backendì˜ ìƒìœ„ í´ë”)
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
BIN_IMAGES_DIR = os.path.join(DATA_DIR, "bin_images")
OUTPUT_DIR = os.path.join(DATA_DIR, "output")

def ensure_directories():
    """í•„ìš”í•œ ë””ë ‰í„°ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±"""
    directories = [DATA_DIR, BIN_IMAGES_DIR, OUTPUT_DIR]
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory, exist_ok=True)
            print(f"âœ… ë””ë ‰í„°ë¦¬ ìƒì„±ë¨: {directory}")
        else:
            print(f"ğŸ“ ë””ë ‰í„°ë¦¬ í™•ì¸ë¨: {directory}")

# PaddleOCR ê´€ë ¨ ì„í¬íŠ¸ ì‹œë„
try:
    import paddle
    from paddleocr import PaddleOCR
    import numpy as np
    from PIL import Image
    from sklearn.cluster import DBSCAN
    PADDLE_OCR_AVAILABLE = True
    print("âœ… PaddleOCR ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    print(f"âš ï¸ PaddleOCR ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    PADDLE_OCR_AVAILABLE = False

# Azure OCR ê´€ë ¨ ì„í¬íŠ¸ ì‹œë„
try:
    from azure.core.credentials import AzureKeyCredential
    from azure.ai.formrecognizer import DocumentAnalysisClient
    AZURE_OCR_AVAILABLE = True
    print("âœ… Azure OCR ì‚¬ìš© ê°€ëŠ¥")
except ImportError as e:
    print(f"âš ï¸ Azure OCR ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    AZURE_OCR_AVAILABLE = False


class OCRResult:
    """OCR ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    def __init__(
        self,
        status: str = "processing",
        extracted_text: str = "",
        word_count: int = 0,
        confidence_score: float = 0.0,
        processing_time: float = 0.0,
        visualization_path: Optional[str] = None,
        error_message: Optional[str] = None,
        ocr_data: Optional[Dict[str, Any]] = None
    ):
        self.status = status
        self.extracted_text = extracted_text
        self.word_count = word_count
        self.confidence_score = confidence_score
        self.processing_time = processing_time
        self.visualization_path = visualization_path
        self.error_message = error_message
        self.ocr_data = ocr_data


def binarize_image(img_path: str, threshold: int = 127):
    """ì´ë¯¸ì§€ ì´ì§„í™” í•¨ìˆ˜"""
    if not PADDLE_OCR_AVAILABLE:
        return None
    
    # ì´ë¯¸ì§€ ì—´ê¸° ë° ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    img = Image.open(img_path).convert('L')  # 'L'ì€ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ëª¨ë“œ
    img_np = np.array(img)
    
    # ì„ê³„ê°’ ì ìš©í•´ ì´ì§„í™” (threshold ì´ˆê³¼: 255, ì´í•˜: 0)
    binarized_np = (img_np > threshold) * 255
    binarized_np = binarized_np.astype(np.uint8)
    
    # NumPy ë°°ì—´ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    binarized_img = Image.fromarray(binarized_np)
    return binarized_img


def sort_text_with_bbox(ocr_result: Dict, debug: bool = False):
    """
    ê³ ë¬¸ì„œ OCR ê²°ê³¼ ì •ë ¬ (ìš°â†’ì¢Œ, ìƒâ†’í•˜)
    DBSCAN í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì—´ êµ¬ë¶„
    """
    if not PADDLE_OCR_AVAILABLE:
        return []
    
    boxes = ocr_result['rec_boxes']
    texts = ocr_result['rec_texts']
    
    # ë°•ìŠ¤ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¬¶ì–´ì„œ ì²˜ë¦¬
    text_boxes = []
    for i, (box, text) in enumerate(zip(boxes, texts)):
        x1, y1, x2, y2 = box
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        height = y2 - y1
        text_boxes.append({
            'text': text,
            'center_x': center_x,
            'center_y': center_y,
            'height': height,
            'box': box,
            'index': i
        })
    
    if debug:
        print("=== ì›ë³¸ ë°ì´í„° ë¶„ì„ ===")
        for i, item in enumerate(text_boxes):
            print(f"{i:2d}: X={item['center_x']:4.0f} Y={item['center_y']:4.0f} H={item['height']:4d} \"{item['text'][:20]}...\"")
    
    # 1ë‹¨ê³„: DBSCANì„ ì‚¬ìš©í•œ ì—´ í´ëŸ¬ìŠ¤í„°ë§
    columns = cluster_columns_dbscan(text_boxes, debug)
    
    # 2ë‹¨ê³„: ê° ì—´ì„ ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ ìˆœì„œë¡œ ì •ë ¬
    columns.sort(key=lambda col: -float(np.mean([item['center_x'] for item in col])))
    
    # 3ë‹¨ê³„: ê° ì—´ ë‚´ì—ì„œ Y ì¢Œí‘œ ê¸°ì¤€ ì •ë ¬ (ìƒâ†’í•˜)
    sorted_text = []
    for col_idx, column in enumerate(columns):
        # ì—´ ë‚´ì—ì„œ Y ì¢Œí‘œ ìˆœìœ¼ë¡œ ì •ë ¬
        column.sort(key=lambda item: item['center_y'])
        
        if debug:
            avg_x = np.mean([item['center_x'] for item in column])
            print(f"\nì—´ {col_idx + 1} (í‰ê·  X: {avg_x:.0f}):")
            for j, item in enumerate(column):
                print(f"  {j+1:2d}: Y={item['center_y']:4.0f} \"{item['text'][:30]}...\"")
        
        sorted_text.extend([item['text'] for item in column])
    
    return sorted_text


def cluster_columns_dbscan(text_boxes, debug: bool = False):
    """DBSCAN í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•œ ì—´ êµ¬ë¶„"""
    if not PADDLE_OCR_AVAILABLE:
        return []
    
    # X ì¢Œí‘œë§Œ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§
    X = np.array([[item['center_x']] for item in text_boxes])
    
    # DBSCAN ë§¤ê°œë³€ìˆ˜ ì¡°ì •
    eps = 120  # í”½ì…€ ë‹¨ìœ„
    min_samples = 1
    
    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
    labels = clustering.labels_
    
    # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê·¸ë£¹í™”
    columns = {}
    for i, label in enumerate(labels):
        if label == -1:  # ë…¸ì´ì¦ˆë¡œ ë¶„ë¥˜ëœ ê²½ìš° ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹
            label = find_nearest_cluster(text_boxes[i], columns)
        
        if label not in columns:
            columns[label] = []
        columns[label].append(text_boxes[i])
    
    if debug:
        print(f"\n=== DBSCAN í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (eps={eps}) ===")
        for label, items in columns.items():
            avg_x = np.mean([item['center_x'] for item in items])
            print(f"í´ëŸ¬ìŠ¤í„° {label}: {len(items)}ê°œ í•­ëª©, í‰ê·  X={avg_x:.0f}")
    
    return list(columns.values())


def find_nearest_cluster(item, clusters):
    """ë…¸ì´ì¦ˆë¡œ ë¶„ë¥˜ëœ í•­ëª©ì„ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹"""
    if not PADDLE_OCR_AVAILABLE or not clusters:
        return 0
    
    min_distance = float('inf')
    nearest_label = 0
    
    for label, cluster_items in clusters.items():
        cluster_center_x = np.mean([ci['center_x'] for ci in cluster_items])
        distance = abs(item['center_x'] - cluster_center_x)
        if distance < min_distance:
            min_distance = distance
            nearest_label = label
    
    return nearest_label


def initialize_paddle_ocr():
    """PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”"""
    if not PADDLE_OCR_AVAILABLE:
        return None
    
    # Paddle ì„¤ì •
    paddle.set_flags({
        "FLAGS_fraction_of_cpu_memory_to_use": 0.5, 
        "FLAGS_eager_delete_tensor_gb": 0.0,
        "FLAGS_fast_eager_deletion_mode": True,
        "FLAGS_use_mkldnn": False,
    })
    
    try:
        # Try OCR with High-performance(hpi)
        ocr = PaddleOCR(
            lang='chinese_cht',
            text_det_limit_side_len=1500,
            text_det_limit_type='max',
            cpu_threads=1,
            use_doc_orientation_classify=True,
            use_doc_unwarping=False,
            use_textline_orientation=False,
            enable_mkldnn=False,
            ocr_version='PP-OCRv5',
            enable_hpi=True,
        )
        return ocr
    except RuntimeError:
        # If failed, go with hpi disabled
        ocr = PaddleOCR(
            lang='chinese_cht',
            text_det_limit_side_len=1500,
            text_det_limit_type='max',
            cpu_threads=1,
            use_doc_orientation_classify=True,
            use_doc_unwarping=False,
            use_textline_orientation=True,
            enable_mkldnn=False,
            ocr_version='PP-OCRv5',
            enable_hpi=False,
            text_det_box_thresh=0.7,
            precision="fp32",
        )
        return ocr


def run_paddle_ocr_analysis(filename: str, ocr_object) -> Optional[Dict[str, Any]]:
    """PaddleOCR ë¶„ì„ ì‹¤í–‰"""
    if not PADDLE_OCR_AVAILABLE or not ocr_object:
        return None
    
    try:
        # ì´ë¯¸ì§€ ì´ì§„í™”
        bin_img = binarize_image(filename, threshold=127)
        if bin_img is None:
            return None
        
        name, ext = os.path.basename(filename).split(".", 1)
        bin_name = name + "_bin." + ext
        bin_path = os.path.join(BIN_IMAGES_DIR, bin_name)
        bin_img.save(bin_path)

        avg_confidence = None

        if os.path.exists(bin_path):
            result = ocr_object.predict(input=bin_path)
            for res in result:
                res.print()
                res.save_to_img(OUTPUT_DIR)
                res.save_to_json(OUTPUT_DIR)
        else:
            print("Binarized Image File Not Found.")
            return None
        
        json_path = os.path.join(OUTPUT_DIR, name + "_bin_res.json")
        res_json = None
        rec_scores = None

        if os.path.exists(json_path):
            with open(json_path, "r") as f:
                res_json = json.load(f)
                rec_scores = res_json["rec_scores"]

        if rec_scores:
            scores = [float(s) for s in rec_scores if s is not None]
            if scores:
                avg_confidence = sum(scores) / len(scores)

        img_path = os.path.join(OUTPUT_DIR, f"{name}_bin_ocr_res_img.jpg")
        vis_img_path = img_path if os.path.exists(img_path) else None

        json_name = bin_name.split(".")[0] + "_res.json"
        json_path = os.path.join(OUTPUT_DIR, json_name)
        
        if os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                ocr_data = json.load(f)
            sorted_texts = sort_text_with_bbox(ocr_data, debug=False)
            
            # ê²°ê³¼ ì¶œë ¥
            print("\n=== ìµœì¢… ì •ë ¬ëœ í…ìŠ¤íŠ¸ ===")
            for i, text in enumerate(sorted_texts, 1):
                print(f"{i:2d}. {text}")
            
            print("\n=== ì—°ê²°ëœ ì „ì²´ í…ìŠ¤íŠ¸ ===")
            full_text = "".join(sorted_texts)
            print(full_text)
            return {
                "full_text": full_text,
                "visualization_path": vis_img_path,  # ì¡´ì¬í•˜ë©´ ê²½ë¡œ, ì—†ìœ¼ë©´ None
                "ocr_data": ocr_data,
                "avg_confidence": avg_confidence
            }
        else:
            print("Json File Not Found.")
            return None
            
    except Exception as e:
        print(f"âŒ PaddleOCR ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def initialize_azure_ocr():
    """Azure OCR í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    if not AZURE_OCR_AVAILABLE:
        return None
    
    endpoint = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT')
    key = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY')
    
    if not endpoint or not key:
        print("âš ï¸ Azure Document Intelligence í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
        return None
    
    try:
        client = DocumentAnalysisClient(
            endpoint=endpoint,
            credential=AzureKeyCredential(key)
        )
        print("âœ… Azure Document Analysis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        return client
    except Exception as e:
        print(f"âŒ Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def run_azure_ocr_analysis(file_path: str, client) -> Dict[str, Any]:
    """Azure OCR ë¶„ì„ ì‹¤í–‰"""
    if not AZURE_OCR_AVAILABLE or not client:
        return {}
    
    try:
        with open(file_path, 'rb') as f:
            image_data = f.read()
        
        print(f"ğŸ“„ Azure OCR ë¶„ì„ ì‹œì‘...")
        print("â³ Azure API í˜¸ì¶œ ì¤‘... (30ì´ˆ - 2ë¶„ ì†Œìš”)")
        
        # Azure Document Analysis API í˜¸ì¶œ
        poller = client.begin_analyze_document("prebuilt-read", document=image_data)
        result = poller.result()
        
        print(f"âœ… Azure ë¶„ì„ ì™„ë£Œ: {len(result.pages)} í˜ì´ì§€")
        
        # ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        ocr_result = {
            "analyzeResult": {
                "pages": [],
                "version": "3.2",
                "apiVersion": "2023-07-31",
                "modelId": "prebuilt-read"
            }
        }
        
        total_words = 0
        total_confidence = 0
        
        for page_idx, page in enumerate(result.pages):
            page_data = {
                "pageNumber": page_idx + 1,
                "words": []
            }
            
            for word in page.words:
                word_data = {
                    "content": word.content,
                    "confidence": word.confidence,
                    "polygon": [
                        coord for point in word.polygon
                        for coord in [point.x, point.y]
                    ]
                }
                page_data["words"].append(word_data)
                total_words += 1
                total_confidence += word.confidence
            
            ocr_result["analyzeResult"]["pages"].append(page_data)
        
        # í†µê³„ ì •ë³´
        avg_confidence = total_confidence / total_words if total_words > 0 else 0
        print(f"âœ… Azure ë¶„ì„ ì™„ë£Œ: {total_words} ë‹¨ì–´, í‰ê·  ì‹ ë¢°ë„ {avg_confidence:.3f}")
        
        return ocr_result
        
    except Exception as e:
        print(f"âŒ Azure OCR ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(f"ğŸ” Traceback: {traceback.format_exc()}")
        return {}


def analyze_document(
    file_path: str,
    engine: str = "paddle",
    extract_text_only: bool = False,
    visualization: bool = True
) -> OCRResult:
    """
    ë¬¸ì„œ OCR ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
    """
    start_time = time.time()
    
    # ë””ë ‰í„°ë¦¬ í™•ì¸ ë° ìƒì„±
    ensure_directories()
    print(f"analuze_doc : {engine}")
    try:
        if engine.lower() == "paddle":
            return analyze_with_paddle(file_path, extract_text_only, visualization, start_time)
        elif engine.lower() == "azure":
            return analyze_with_azure(file_path, extract_text_only, visualization, start_time)
        else:
            processing_time = time.time() - start_time
            return OCRResult(
                status="failed",
                error_message=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—”ì§„: {engine}. 'paddle' ë˜ëŠ” 'azure'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
                processing_time=processing_time
            )
    
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"âŒ OCR ë¶„ì„ ì˜¤ë¥˜: {traceback.format_exc() if DEBUG_FLAG else e}")
        return OCRResult(
            status="failed",
            error_message=str(e),
            processing_time=processing_time
        )


def analyze_with_paddle(
    file_path: str,
    extract_text_only: bool = False,
    visualization: bool = True,
    start_time: Optional[float] = None
) -> OCRResult:
    """PaddleOCRë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ë¶„ì„"""
    if start_time is None:
        start_time = time.time()
    
    if not PADDLE_OCR_AVAILABLE:
        processing_time = time.time() - start_time
        return OCRResult(
            status="failed",
            error_message="PaddleOCRë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            processing_time=processing_time
        )
    
    try:
        print(f"ğŸ” PaddleOCRë¡œ ë¶„ì„ ì‹œì‘: {file_path}")
        
        # PaddleOCR ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        ocr_instance = initialize_paddle_ocr()
        if not ocr_instance:
            processing_time = time.time() - start_time
            return OCRResult(
                status="failed",
                error_message="PaddleOCR ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                processing_time=processing_time
            )
        
        # PaddleOCR ì‹¤í–‰
        paddle_resp = run_paddle_ocr_analysis(file_path, ocr_instance)
        
        if not paddle_resp:
            processing_time = time.time() - start_time
            return OCRResult(
                status="failed",
                error_message="PaddleOCRì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                processing_time=processing_time
            )
        
        extracted_text = paddle_resp.get("full_text", "")
        vis_path = paddle_resp.get("visualization_path")
        ocr_data = paddle_resp.get("ocr_data")

        # ë‹¨ì–´ ìˆ˜ ê³„ì‚°
        word_count = len(extracted_text.replace(" ", ""))  # í•œêµ­ì–´/ì¤‘êµ­ì–´ì˜ ê²½ìš° ê³µë°± ì œê±° í›„ ë¬¸ì ìˆ˜
        
        # ì‹ ë¢°ë„ ì ìˆ˜
        avg_confidence = paddle_resp.get("avg_confidence")
        confidence_score = float(avg_confidence) if avg_confidence is not None else 0.0

        visualization_path = vis_path if visualization else None
        processing_time = time.time() - start_time
        
        print(f"âœ… PaddleOCR ë¶„ì„ ì™„ë£Œ: {word_count}ì, {processing_time:.2f}ì´ˆ")
        
        return OCRResult(
            status="completed",
            extracted_text=extracted_text,
            word_count=word_count,
            confidence_score=confidence_score,
            processing_time=processing_time,
            visualization_path=visualization_path,
            ocr_data = ocr_data
            # ocr_data={"engine": "paddle", "raw_text": extracted_text} if not extract_text_only else None
        )
    
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"âŒ PaddleOCR ë¶„ì„ ì˜¤ë¥˜: {traceback.format_exc() if DEBUG_FLAG else e}")
        return OCRResult(
            status="failed",
            error_message=f"PaddleOCR ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
            processing_time=processing_time
        )


def analyze_with_azure(
    file_path: str,
    extract_text_only: bool = False,
    visualization: bool = True,
    start_time: Optional[float] = None
) -> OCRResult:
    """Azure Document Intelligenceë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ë¶„ì„"""
    if start_time is None:
        start_time = time.time()
    
    if not AZURE_OCR_AVAILABLE:
        processing_time = time.time() - start_time
        return OCRResult(
            status="failed",
            error_message="AzureOCRë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            processing_time=processing_time
        )
    
    try:
        print(f"ğŸ” Azure OCRë¡œ ë¶„ì„ ì‹œì‘: {file_path}")
        
        # Azure OCR í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = initialize_azure_ocr()
        if not client:
            processing_time = time.time() - start_time
            return OCRResult(
                status="failed",
                error_message="Azure OCR í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                processing_time=processing_time
            )
        
        # Azure OCR ë¶„ì„ ì‹¤í–‰
        ocr_data = run_azure_ocr_analysis(file_path, client)
        
        if not ocr_data:
            processing_time = time.time() - start_time
            return OCRResult(
                status="failed",
                error_message="Azure OCRì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                processing_time=processing_time
            )
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í†µê³„ ê³„ì‚°
        extracted_text = ""
        total_confidence = 0.0
        word_count = 0
        
        for page in ocr_data["analyzeResult"]["pages"]:
            for word in page["words"]:
                extracted_text += word["content"]
                total_confidence += word["confidence"]
                word_count += 1
        
        confidence_score = total_confidence / word_count if word_count > 0 else 0.0
        processing_time = time.time() - start_time
        
        # ì‹œê°í™”ëŠ” Azureì—ì„œ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ None
        visualization_path = None
        if visualization:
            print("âš ï¸ Azure OCR ì‹œê°í™”ëŠ” í˜„ì¬ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… Azure OCR ë¶„ì„ ì™„ë£Œ: {word_count}ë‹¨ì–´, ì‹ ë¢°ë„ {confidence_score:.3f}, {processing_time:.2f}ì´ˆ")
        
        return OCRResult(
            status="completed",
            extracted_text=extracted_text,
            word_count=word_count,
            confidence_score=confidence_score,
            processing_time=processing_time,
            visualization_path=visualization_path,
            ocr_data=ocr_data if not extract_text_only else None
        )
    
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"âŒ Azure OCR ë¶„ì„ ì˜¤ë¥˜: {traceback.format_exc() if DEBUG_FLAG else e}")
        return OCRResult(
            status="failed",
            error_message=f"Azure OCR ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
            processing_time=processing_time
        )


def get_available_engines() -> Dict[str, bool]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ OCR ì—”ì§„ ëª©ë¡ ë°˜í™˜"""
    return {
        "paddle": PADDLE_OCR_AVAILABLE,
        "azure": AZURE_OCR_AVAILABLE
    }


def validate_image_file(file_path: str) -> bool:
    """ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
    if not os.path.exists(file_path):
        return False
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']
    _, ext = os.path.splitext(file_path.lower())
    
    return ext in valid_extensions