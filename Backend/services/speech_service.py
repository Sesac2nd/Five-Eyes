import os
import io
import base64
import tempfile
import logging
from typing import Dict, Optional, List
from config.settings import settings

logger = logging.getLogger(__name__)


class SpeechService:
    """Azure Speech Serviceë¥¼ ì´ìš©í•œ STT/TTS ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.enabled = False
        self.speech_key = settings.AZURE_SPEECH_KEY
        self.speech_region = settings.AZURE_SPEECH_REGION
        self._initialize_service()

    def _initialize_service(self):
        """Azure Speech Service ì´ˆê¸°í™”"""
        try:
            if not self.speech_key or self.speech_key == "":
                logger.error("âŒ Azure Speech Service í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            if not self.speech_region or self.speech_region == "":
                logger.error("âŒ Azure Speech Service ë¦¬ì „ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return

            # Azure Speech SDK import í™•ì¸
            import azure.cognitiveservices.speech as speechsdk

            # ê¸°ë³¸ ì„¤ì • í…ŒìŠ¤íŠ¸
            speech_config = speechsdk.SpeechConfig(
                subscription=self.speech_key, region=self.speech_region
            )

            self.enabled = True
            logger.info("âœ… Azure Speech Service ì´ˆê¸°í™” ì„±ê³µ")

        except ImportError:
            logger.error("âŒ Azure Speech SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info("ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: pip install azure-cognitiveservices-speech")
        except Exception as e:
            logger.error(f"âŒ Azure Speech Service ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def text_to_speech(
        self,
        text: str,
        voice_name: str = "ko-KR-HyunsuMultilingualNeural",
        output_format: str = "wav",
    ) -> Dict:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        if not self.enabled:
            return {
                "success": False,
                "error": "Azure Speech Serviceê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "audio_data": None,
            }

        try:
            import azure.cognitiveservices.speech as speechsdk

            # Speech ì„¤ì •
            speech_config = speechsdk.SpeechConfig(
                subscription=self.speech_key, region=self.speech_region
            )
            speech_config.speech_synthesis_voice_name = voice_name

            # ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì • (ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë¦¼)
            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=False)
            speech_synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config, audio_config=audio_config
            )

            # ìŒì„± í•©ì„± ì‹¤í–‰
            logger.info(f"ğŸ”Š TTS ìš”ì²­: '{text[:50]}...' (ìŒì„±: {voice_name})")
            result = speech_synthesizer.speak_text_async(text).get()

            # ê²°ê³¼ í™•ì¸
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                # Base64ë¡œ ì¸ì½”ë”©
                audio_base64 = base64.b64encode(result.audio_data).decode("utf-8")

                logger.info(f"âœ… TTS ì„±ê³µ: {len(result.audio_data)} bytes")

                return {
                    "success": True,
                    "audio_data": audio_base64,
                    "audio_size": len(result.audio_data),
                    "voice_name": voice_name,
                    "text": text,
                    "format": output_format,
                }

            elif result.reason == speechsdk.ResultReason.Canceled:
                cancellation_details = result.cancellation_details
                error_msg = f"TTS ì·¨ì†Œë¨: {cancellation_details.reason}"

                if cancellation_details.reason == speechsdk.CancellationReason.Error:
                    error_msg += f" - {cancellation_details.error_details}"

                logger.error(f"âŒ {error_msg}")
                return {"success": False, "error": error_msg, "audio_data": None}
            else:
                return {
                    "success": False,
                    "error": "ìŒì„± í•©ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    "audio_data": None,
                }

        except Exception as e:
            logger.error(f"âŒ TTS ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"ìŒì„± í•©ì„± ì˜¤ë¥˜: {str(e)}",
                "audio_data": None,
            }

    def speech_to_text(
        self, audio_data: bytes, language: str = "ko-KR", audio_format: str = "wav"
    ) -> Dict:
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not self.enabled:
            return {
                "success": False,
                "error": "Azure Speech Serviceê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "recognized_text": "",
            }

        try:
            import azure.cognitiveservices.speech as speechsdk

            # Speech ì„¤ì •
            speech_config = speechsdk.SpeechConfig(
                subscription=self.speech_key, region=self.speech_region
            )
            speech_config.speech_recognition_language = language

            # ì¹¨ë¬µ ê°ì§€ ì‹œê°„ ì„¤ì • (8ì´ˆ)
            speech_config.set_property(
                speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, "8000"
            )

            # ì„ì‹œ íŒŒì¼ë¡œ ì˜¤ë””ì˜¤ ì €ì¥
            with tempfile.NamedTemporaryFile(
                suffix=f".{audio_format}", delete=False
            ) as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name

            try:
                # íŒŒì¼ ê¸°ë°˜ ì˜¤ë””ì˜¤ ì„¤ì •
                audio_config = speechsdk.audio.AudioConfig(filename=temp_file_path)
                speech_recognizer = speechsdk.SpeechRecognizer(
                    speech_config=speech_config, audio_config=audio_config
                )

                logger.info(f"ğŸ¤ STT ìš”ì²­: {len(audio_data)} bytes ({language})")

                # ìŒì„± ì¸ì‹ ì‹¤í–‰
                result = speech_recognizer.recognize_once_async().get()

                if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                    recognized_text = result.text.strip()
                    logger.info(f"âœ… STT ì„±ê³µ: '{recognized_text}'")

                    return {
                        "success": True,
                        "recognized_text": recognized_text,
                        "confidence": 0.85,  # AzureëŠ” ì‹ ë¢°ë„ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                        "language": language,
                        "audio_duration": len(audio_data) / 16000,  # ëŒ€ëµì ì¸ ì¶”ì •
                    }

                elif result.reason == speechsdk.ResultReason.NoMatch:
                    logger.warning("âš ï¸ STT: ìŒì„± ë§¤ì¹­ ì—†ìŒ")
                    return {
                        "success": False,
                        "error": "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ëª…í™•í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "recognized_text": "",
                    }

                elif result.reason == speechsdk.ResultReason.Canceled:
                    cancellation_details = result.cancellation_details
                    error_msg = f"STT ì·¨ì†Œë¨: {cancellation_details.reason}"

                    if (
                        cancellation_details.reason
                        == speechsdk.CancellationReason.Error
                    ):
                        error_msg += f" - {cancellation_details.error_details}"

                    logger.error(f"âŒ {error_msg}")
                    return {"success": False, "error": error_msg, "recognized_text": ""}
                else:
                    return {
                        "success": False,
                        "error": "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                        "recognized_text": "",
                    }

            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.remove(temp_file_path)
                except:
                    pass

        except Exception as e:
            logger.error(f"âŒ STT ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}",
                "recognized_text": "",
            }

    def get_available_voices(self, language: str = "ko-KR") -> Dict:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ì¡°íšŒ"""
        korean_voices = [
            {
                "name": "ko-KR-HyunsuMultilingualNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„± ìŒì„± (ë‹¤êµ­ì–´ ì§€ì›)",
                "recommended": True,
            },
            {
                "name": "ko-KR-SunHiNeural",
                "gender": "Female",
                "description": "í•œêµ­ì–´ ì—¬ì„± ìŒì„±",
                "recommended": True,
            },
            {
                "name": "ko-KR-InJoonNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„± ìŒì„±",
            },
            {
                "name": "ko-KR-BongJinNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„± ìŒì„±",
            },
            {
                "name": "ko-KR-GookMinNeural",
                "gender": "Male",
                "description": "í•œêµ­ì–´ ë‚¨ì„± ìŒì„±",
            },
        ]

        chinese_voices = [
            {
                "name": "zh-CN-XiaoxiaoNeural",
                "gender": "Female",
                "description": "ì¤‘êµ­ì–´ ê°„ì²´ ì—¬ì„± ìŒì„±",
            },
            {
                "name": "zh-CN-YunxiNeural",
                "gender": "Male",
                "description": "ì¤‘êµ­ì–´ ê°„ì²´ ë‚¨ì„± ìŒì„±",
            },
            {
                "name": "zh-TW-HsiaoChenNeural",
                "gender": "Female",
                "description": "ì¤‘êµ­ì–´ ë²ˆì²´ ì—¬ì„± ìŒì„±",
            },
        ]

        if language.startswith("ko"):
            return {
                "language": language,
                "voices": korean_voices,
                "default": "ko-KR-HyunsuMultilingualNeural",
            }
        elif language.startswith("zh"):
            return {
                "language": language,
                "voices": chinese_voices,
                "default": "zh-CN-XiaoxiaoNeural",
            }
        else:
            return {
                "language": language,
                "voices": korean_voices + chinese_voices,
                "default": "ko-KR-HyunsuMultilingualNeural",
            }

    def create_ssml(
        self, text: str, voice_name: str, rate: str = "medium", pitch: str = "medium"
    ) -> str:
        """SSML í˜•ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜"""
        ssml = f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">
            <voice name="{voice_name}">
                <prosody rate="{rate}" pitch="{pitch}">
                    {text}
                </prosody>
            </voice>
        </speak>
        """
        return ssml.strip()

    def text_to_speech_with_ssml(self, ssml: str) -> Dict:
        """SSMLì„ ì‚¬ìš©í•œ ê³ ê¸‰ ìŒì„± í•©ì„±"""
        if not self.enabled:
            return {
                "success": False,
                "error": "Azure Speech Serviceê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "audio_data": None,
            }

        try:
            import azure.cognitiveservices.speech as speechsdk

            # Speech ì„¤ì •
            speech_config = speechsdk.SpeechConfig(
                subscription=self.speech_key, region=self.speech_region
            )

            # ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì •
            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=False)
            speech_synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config, audio_config=audio_config
            )

            # SSMLë¡œ ìŒì„± í•©ì„±
            result = speech_synthesizer.speak_ssml_async(ssml).get()

            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                audio_base64 = base64.b64encode(result.audio_data).decode("utf-8")

                return {
                    "success": True,
                    "audio_data": audio_base64,
                    "audio_size": len(result.audio_data),
                    "ssml": ssml,
                }
            else:
                return {
                    "success": False,
                    "error": "SSML ìŒì„± í•©ì„± ì‹¤íŒ¨",
                    "audio_data": None,
                }

        except Exception as e:
            logger.error(f"âŒ SSML TTS ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": f"SSML ìŒì„± í•©ì„± ì˜¤ë¥˜: {str(e)}",
                "audio_data": None,
            }

    def get_service_info(self) -> Dict:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "Azure Speech Service",
            "enabled": self.enabled,
            "region": self.speech_region if self.enabled else "Not configured",
            "features": [
                "í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜ (TTS)",
                "ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ (STT)",
                "ë‹¤êµ­ì–´ ì§€ì›",
                "SSML ì§€ì›",
                "ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹",
            ],
            "supported_languages": [
                "ko-KR (í•œêµ­ì–´)",
                "zh-CN (ì¤‘êµ­ì–´ ê°„ì²´)",
                "zh-TW (ì¤‘êµ­ì–´ ë²ˆì²´)",
                "ja-JP (ì¼ë³¸ì–´)",
                "en-US (ì˜ì–´)",
            ],
            "audio_formats": ["WAV", "MP3", "OGG"],
        }


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
speech_service = SpeechService()
