{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37d50e1",
   "metadata": {},
   "source": [
    "### 2. Azure Document Intelligence ê¸°ë°˜ ì—­ì‚¬ë¬¸ì„œ OCR ë¶„ì„ ë° PIL ì‹œê°í™”\n",
    "- ì£¼ìš” ì—­í• : Azure Document Intelligence OCR ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ë¡œì¤„ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ì‹œê°í™”\n",
    "- í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬: PIL(Pillow), Azure Document Intelligence, matplotlib\n",
    "- íŠ¹ì§•: í•œê¸€ ê²½ë¡œ ì§€ì›, ì„¸ë¡œì¤„ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„, ì‹ ë¢°ë„ í†µê³„ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d71ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\el76\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\el76\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\el76\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python pillow matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7383a79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-documentintelligence in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-documentintelligence) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-documentintelligence) (1.35.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\el76\\appdata\\roaming\\python\\python311\\site-packages (from azure-ai-documentintelligence) (4.14.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-documentintelligence) (2.32.4)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\el76\\appdata\\roaming\\python\\python311\\site-packages (from azure-core>=1.30.0->azure-ai-documentintelligence) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\el76\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install azure-ai-documentintelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1662a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Azure Document Intelligence OCR ì™„ì „ ë¶„ì„ ë„êµ¬\n",
    "- ì‹¤ì‹œê°„ Azure API í˜¸ì¶œ ë° OCR ë¶„ì„\n",
    "- í•œì/ê³ ë¬¸ì„œ ì‹œê°í™” ì§€ì›\n",
    "- ì„¤ì • íŒŒì¼ ìë™ ìƒì„±\n",
    "- í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ë³´ì•ˆ ì„¤ì •\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.font_manager as fm\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import platform\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ python-dotenv ì„¤ì¹˜ í•„ìš”: pip install python-dotenv\")\n",
    "\n",
    "# Azure SDK imports\n",
    "try:\n",
    "    from azure.core.credentials import AzureKeyCredential\n",
    "    from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "    from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "    AZURE_SDK_AVAILABLE = True\n",
    "    print(\"âœ… Azure SDK ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    AZURE_SDK_AVAILABLE = False\n",
    "    print(\"âŒ Azure SDK ì—†ìŒ. ì„¤ì¹˜ í•„ìš”: pip install azure-ai-documentintelligence\")\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "warnings.filterwarnings('ignore', message='Glyph.*missing from font')\n",
    "\n",
    "\n",
    "class CompleteAzureOCRAnalyzer:\n",
    "    \"\"\"ì™„ì „í•œ Azure Document Intelligence OCR ë¶„ì„ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        ì´ˆê¸°í™”\n",
    "        Args:\n",
    "            config_path: Azure ì„¤ì • íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)\n",
    "        \"\"\"\n",
    "        print(\"ğŸš€ Azure OCR ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...\")\n",
    "        \n",
    "        # ìƒ‰ìƒ ì •ì˜\n",
    "        self.colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', \n",
    "                      'pink', 'gray', 'olive', 'cyan']\n",
    "        \n",
    "        # Azure ì„¤ì • ë¡œë“œ\n",
    "        self.config = self._load_azure_config(config_path)\n",
    "        self.document_client = None\n",
    "        \n",
    "        # í°íŠ¸ ì„¤ì •\n",
    "        self.han_font = self._setup_cjk_font()\n",
    "        self._configure_matplotlib()\n",
    "        \n",
    "        print(f\"âœ… ì´ˆê¸°í™” ì™„ë£Œ - í°íŠ¸: {self._get_font_name()}\")\n",
    "    \n",
    "    def _load_azure_config(self, config_path: Optional[str]) -> Dict:\n",
    "        \"\"\"Azure ì„¤ì • ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ ìš°ì„  > ì„¤ì •íŒŒì¼)\"\"\"\n",
    "        config = {}\n",
    "        \n",
    "        # 1. í™˜ê²½ë³€ìˆ˜ ìš°ì„  í™•ì¸ (ë³´ì•ˆìƒ ê¶Œì¥)\n",
    "        env_endpoint = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT')\n",
    "        env_key = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY')\n",
    "        \n",
    "        if env_endpoint and env_key:\n",
    "            config['endpoint'] = env_endpoint\n",
    "            config['key'] = env_key\n",
    "            print(\"âœ… í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ Azure ì„¤ì • ë¡œë“œ\")\n",
    "            return config\n",
    "        \n",
    "        print(\"âš ï¸ í™˜ê²½ë³€ìˆ˜ì— Azure ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì • íŒŒì¼ì„ í™•ì¸í•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # 2. ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ê°€ ì—†ì„ ë•Œë§Œ)\n",
    "        config_files = [\n",
    "            config_path,\n",
    "            'azure_config.json',\n",
    "            'config.json',\n",
    "            'azure_config_template.json'  # í…œí”Œë¦¿ íŒŒì¼ì€ ë§ˆì§€ë§‰ì—\n",
    "        ]\n",
    "        \n",
    "        for file_path in config_files:\n",
    "            if file_path and os.path.exists(file_path):\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        file_config = json.load(f)\n",
    "                        endpoint = file_config.get('endpoint', '')\n",
    "                        key = file_config.get('key', '')\n",
    "                        \n",
    "                        # ì‹¤ì œ Azure ì„¤ì •ì¸ì§€ í™•ì¸ (í…œí”Œë¦¿ ê°’ì´ ì•„ë‹Œì§€)\n",
    "                        if (endpoint and key and \n",
    "                            not endpoint.startswith('https://your-resource') and\n",
    "                            not key.startswith('your-32-character')):\n",
    "                            config.update(file_config)\n",
    "                            print(f\"âœ… ì„¤ì • íŒŒì¼ì—ì„œ Azure ì„¤ì • ë¡œë“œ: {file_path}\")\n",
    "                            return config\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ í…œí”Œë¦¿ ì„¤ì • íŒŒì¼ ê±´ë„ˆëœ€: {file_path}\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ ì„¤ì • íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path} - {e}\")\n",
    "        \n",
    "        print(\"âŒ Azure ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ .env íŒŒì¼ì— AZURE_DOCUMENT_INTELLIGENCE_ENDPOINTì™€ AZURE_DOCUMENT_INTELLIGENCE_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "        return config\n",
    "    \n",
    "    def setup_azure_client(self) -> bool:\n",
    "        \"\"\"Azure Document Intelligence í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\"\"\"\n",
    "        if not AZURE_SDK_AVAILABLE:\n",
    "            print(\"âŒ Azure SDK ì„¤ì¹˜ í•„ìš”:\")\n",
    "            print(\"pip install azure-ai-documentintelligence\")\n",
    "            return False\n",
    "        \n",
    "        endpoint = self.config.get('endpoint')\n",
    "        key = self.config.get('key')\n",
    "        \n",
    "        if not endpoint or not key:\n",
    "            print(\"âŒ Azure ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            self._show_azure_setup_guide()\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            self.document_client = DocumentIntelligenceClient(\n",
    "                endpoint=endpoint,\n",
    "                credential=AzureKeyCredential(key)\n",
    "            )\n",
    "            print(\"âœ… Azure Document Intelligence í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Azure í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _show_azure_setup_guide(self):\n",
    "        \"\"\"Azure ì„¤ì • ê°€ì´ë“œ ì¶œë ¥\"\"\"\n",
    "        print(\"\\nğŸ“ Azure Document Intelligence ì„¤ì • ê°€ì´ë“œ:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ê¶Œì¥ ë°©ë²• - .env íŒŒì¼ ì‚¬ìš©:\")\n",
    "        print(\"1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ ìƒì„±\")\n",
    "        print(\"2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:\")\n",
    "        print(\"   AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/\")\n",
    "        print(\"   AZURE_DOCUMENT_INTELLIGENCE_KEY=your-api-key-here\")\n",
    "        print(\"\\nëŒ€ì•ˆ ë°©ë²• - config.json íŒŒì¼:\")\n",
    "        print('{\"endpoint\": \"https://your-resource.cognitiveservices.azure.com/\", \"key\": \"your-api-key\"}')\n",
    "        print(\"\\nìë™ í…œí”Œë¦¿ ìƒì„±:\")\n",
    "        print(\"create_azure_config() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    # ...existing code... (analyze_document_live ë©”ì„œë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "    \n",
    "    def analyze_document_live(self, image_path: str) -> Optional[Dict]:\n",
    "        \"\"\"ì‹¤ì‹œê°„ Azure Document Intelligence ë¶„ì„\"\"\"\n",
    "        if not self.setup_azure_client():\n",
    "            return None\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ“„ Azureë¡œ ë¬¸ì„œ ë¶„ì„ ì¤‘: {os.path.basename(image_path)}\")\n",
    "            print(\"â³ ë¶„ì„ ì§„í–‰ ì¤‘... (30ì´ˆ-2ë¶„ ì†Œìš”)\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°\n",
    "            with open(image_path, 'rb') as f:\n",
    "                image_data = f.read()\n",
    "            \n",
    "            # Azure Document Intelligence API í˜¸ì¶œ\n",
    "            poller = self.document_client.begin_analyze_document(\n",
    "                \"prebuilt-read\",\n",
    "                AnalyzeDocumentRequest(bytes_source=image_data)\n",
    "            )\n",
    "            \n",
    "            # ê²°ê³¼ ëŒ€ê¸°\n",
    "            result = poller.result()\n",
    "            \n",
    "            # í‘œì¤€ JSON í˜•íƒœë¡œ ë³€í™˜\n",
    "            ocr_result = {\n",
    "                \"analyzeResult\": {\n",
    "                    \"pages\": [],\n",
    "                    \"version\": \"4.0\",\n",
    "                    \"apiVersion\": \"2024-02-29-preview\",\n",
    "                    \"modelId\": \"prebuilt-read\",\n",
    "                    \"stringIndexType\": \"textElements\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            total_words = 0\n",
    "            total_confidence = 0\n",
    "            \n",
    "            for page_idx, page in enumerate(result.pages):\n",
    "                page_data = {\n",
    "                    \"pageNumber\": page_idx + 1,\n",
    "                    \"words\": []\n",
    "                }\n",
    "                \n",
    "                if hasattr(page, 'words') and page.words:\n",
    "                    for word in page.words:\n",
    "                        word_data = {\n",
    "                            \"content\": word.content,\n",
    "                            \"confidence\": word.confidence if hasattr(word, 'confidence') else 0.9,\n",
    "                            \"polygon\": list(word.polygon) if hasattr(word, 'polygon') else [],\n",
    "                            \"span\": {\n",
    "                                \"offset\": word.span.offset if hasattr(word, 'span') else 0,\n",
    "                                \"length\": word.span.length if hasattr(word, 'span') else len(word.content)\n",
    "                            }\n",
    "                        }\n",
    "                        page_data[\"words\"].append(word_data)\n",
    "                        total_words += 1\n",
    "                        total_confidence += word_data[\"confidence\"]\n",
    "                \n",
    "                ocr_result[\"analyzeResult\"][\"pages\"].append(page_data)\n",
    "            \n",
    "            # ë¶„ì„ ê²°ê³¼ í†µê³„\n",
    "            avg_confidence = total_confidence / total_words if total_words > 0 else 0\n",
    "            print(f\"âœ… Azure ë¶„ì„ ì™„ë£Œ:\")\n",
    "            print(f\"   ğŸ“Š ì´ {total_words}ê°œ ë‹¨ì–´ ì¸ì‹\")\n",
    "            print(f\"   ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
    "            \n",
    "            # ê²°ê³¼ ìë™ ì €ì¥\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            auto_save_path = f\"{Path(image_path).stem}_azure_ocr_{timestamp}.json\"\n",
    "            self._save_ocr_result(ocr_result, auto_save_path)\n",
    "            \n",
    "            return ocr_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Azure ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # ...existing code... (ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "    \n",
    "    def _save_ocr_result(self, ocr_data: Dict, file_path: str):\n",
    "        \"\"\"OCR ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(ocr_data, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"ğŸ’¾ OCR ê²°ê³¼ ì €ì¥: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    def _get_font_name(self) -> str:\n",
    "        \"\"\"í°íŠ¸ ì´ë¦„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ\"\"\"\n",
    "        try:\n",
    "            if hasattr(self.han_font, 'get_name'):\n",
    "                return self.han_font.get_name()\n",
    "            elif hasattr(self.han_font, '_family'):\n",
    "                family = self.han_font._family\n",
    "                return family[0] if isinstance(family, list) else str(family)\n",
    "            else:\n",
    "                return \"ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸\"\n",
    "        except:\n",
    "            return \"í°íŠ¸ ì •ë³´ í™•ì¸ ë¶ˆê°€\"\n",
    "    \n",
    "    def _setup_cjk_font(self):\n",
    "        \"\"\"CJK(í•œì¤‘ì¼) í°íŠ¸ ì„¤ì •\"\"\"\n",
    "        system = platform.system()\n",
    "        \n",
    "        # Windows í°íŠ¸ ìš°ì„ ìˆœìœ„\n",
    "        if system == \"Windows\":\n",
    "            font_candidates = [\n",
    "                (\"C:/Windows/Fonts/simsun.ttc\", \"SimSun\"),      # ì¤‘êµ­ì–´ - í•œì ì™„ì „ ì§€ì›\n",
    "                (\"C:/Windows/Fonts/msyh.ttc\", \"Microsoft YaHei\"), # ì¤‘êµ­ì–´\n",
    "                (\"C:/Windows/Fonts/batang.ttc\", \"Batang\"),       # í•œêµ­ì–´\n",
    "                (\"C:/Windows/Fonts/gulim.ttc\", \"Gulim\"),         # í•œêµ­ì–´\n",
    "                (\"C:/Windows/Fonts/malgun.ttf\", \"Malgun Gothic\"), # í•œêµ­ì–´\n",
    "            ]\n",
    "            \n",
    "            # íŒŒì¼ ê²½ë¡œë¡œ ì§ì ‘ ë¡œë“œ\n",
    "            for font_path, font_name in font_candidates:\n",
    "                if os.path.exists(font_path):\n",
    "                    try:\n",
    "                        return fm.FontProperties(fname=font_path)\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            # ì‹œìŠ¤í…œ í°íŠ¸ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰\n",
    "            system_fonts = [\"SimSun\", \"Microsoft YaHei\", \"Batang\", \"Malgun Gothic\"]\n",
    "            available_fonts = {f.name for f in fm.fontManager.ttflist}\n",
    "            \n",
    "            for font_name in system_fonts:\n",
    "                if font_name in available_fonts:\n",
    "                    try:\n",
    "                        return fm.FontProperties(family=font_name)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        # macOS\n",
    "        elif system == \"Darwin\":\n",
    "            macos_fonts = [\"PingFang SC\", \"Hiragino Sans GB\", \"STSong\"]\n",
    "            available_fonts = {f.name for f in fm.fontManager.ttflist}\n",
    "            \n",
    "            for font_name in macos_fonts:\n",
    "                if font_name in available_fonts:\n",
    "                    try:\n",
    "                        return fm.FontProperties(family=font_name)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        # Linux\n",
    "        else:\n",
    "            linux_fonts = [\"Noto Sans CJK SC\", \"Source Han Sans\", \"WenQuanYi Micro Hei\"]\n",
    "            available_fonts = {f.name for f in fm.fontManager.ttflist}\n",
    "            \n",
    "            for font_name in linux_fonts:\n",
    "                if font_name in available_fonts:\n",
    "                    try:\n",
    "                        return fm.FontProperties(family=font_name)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        return fm.FontProperties()  # ê¸°ë³¸ í°íŠ¸\n",
    "    \n",
    "    def _configure_matplotlib(self):\n",
    "        \"\"\"matplotlib ì „ì—­ ì„¤ì •\"\"\"\n",
    "        try:\n",
    "            font_name = self._get_font_name()\n",
    "            if font_name not in [\"ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸\", \"í°íŠ¸ ì •ë³´ í™•ì¸ ë¶ˆê°€\"]:\n",
    "                plt.rcParams['font.family'] = [font_name, 'sans-serif']\n",
    "            \n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "            plt.rcParams['font.size'] = 12\n",
    "            \n",
    "        except Exception:\n",
    "            plt.rcParams['font.family'] = ['sans-serif']\n",
    "            plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    def group_words_by_vertical_lines(self, words_data: List[Dict], threshold: float = 50) -> List[List[Dict]]:\n",
    "        \"\"\"ë‹¨ì–´ë“¤ì„ ì„¸ë¡œì¤„ë¡œ ê·¸ë£¹í™”\"\"\"\n",
    "        if not words_data:\n",
    "            return []\n",
    "        \n",
    "        sorted_words = sorted(words_data, key=lambda w: w['polygon'][0])\n",
    "        vertical_lines = []\n",
    "        current_line = [sorted_words[0]]\n",
    "        \n",
    "        for word in sorted_words[1:]:\n",
    "            current_line_avg_x = sum(w['polygon'][0] for w in current_line) / len(current_line)\n",
    "            current_word_x = word['polygon'][0]\n",
    "            \n",
    "            if abs(current_word_x - current_line_avg_x) <= threshold:\n",
    "                current_line.append(word)\n",
    "            else:\n",
    "                current_line.sort(key=lambda w: w['polygon'][1])\n",
    "                vertical_lines.append(current_line)\n",
    "                current_line = [word]\n",
    "        \n",
    "        if current_line:\n",
    "            current_line.sort(key=lambda w: w['polygon'][1])\n",
    "            vertical_lines.append(current_line)\n",
    "        \n",
    "        return vertical_lines\n",
    "    \n",
    "    def create_dual_visualization(self, image_path: str, ocr_data: Dict, save_path: Optional[str] = None):\n",
    "        \"\"\"ì¢Œìš° êµ¬ì„± ì‹œê°í™” ìƒì„±\"\"\"\n",
    "        print(f\"ğŸ¨ ì‹œê°í™” ìƒì„±: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # ë‹¨ì–´ ë°ì´í„° ì¶”ì¶œ\n",
    "        words_data = []\n",
    "        for page in ocr_data[\"analyzeResult\"][\"pages\"]:\n",
    "            words_data.extend(page[\"words\"])\n",
    "        \n",
    "        if not words_data:\n",
    "            print(\"âŒ OCR ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"ğŸ“Š ì´ {len(words_data)}ê°œ ë‹¨ì–´ ì¶”ì¶œ\")\n",
    "        \n",
    "        # ì„¸ë¡œì¤„ ê·¸ë£¹í™”\n",
    "        vertical_lines = self.group_words_by_vertical_lines(words_data)\n",
    "        print(f\"ğŸ“Š {len(vertical_lines)}ê°œ ì„¸ë¡œì¤„ë¡œ ê·¸ë£¹í™”\")\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        try:\n",
    "            original_image = Image.open(image_path)\n",
    "            width, height = original_image.size\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # ì¢Œì¸¡: ìƒ‰ìƒ ë°•ìŠ¤ ì´ë¯¸ì§€ ìƒì„±\n",
    "        boxed_image = self._create_colored_boxes(image_path, vertical_lines)\n",
    "        \n",
    "        # ìš°ì¸¡: í†µê³„ ë° ë¸”ëŸ­ ìƒì„±\n",
    "        line_stats = self._create_line_statistics(vertical_lines)\n",
    "        \n",
    "        # matplotlib ì‹œê°í™”\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 16))\n",
    "        \n",
    "        # ì¢Œì¸¡ íŒ¨ë„\n",
    "        axes[0].imshow(boxed_image)\n",
    "        axes[0].set_title('ì„¸ë¡œì¤„ë³„ ìƒ‰ìƒ ë°•ìŠ¤ ì‹œê°í™”', fontproperties=self.han_font, fontsize=8)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # ìš°ì¸¡ íŒ¨ë„\n",
    "        white_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
    "        axes[1].imshow(white_image)\n",
    "        axes[1].set_title('í•œì ì§€ì› í…ìŠ¤íŠ¸ ë¸”ëŸ­ ë°©ì‹', fontproperties=self.han_font, fontsize=8)\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # ìš°ì¸¡ íŒ¨ë„ì— í…ìŠ¤íŠ¸ ë¸”ëŸ­ ì¶”ê°€\n",
    "        rendered_count = 0\n",
    "        total_count = 0\n",
    "        \n",
    "        for idx, (line_name, stats) in enumerate(line_stats.items()):\n",
    "            x, y, w, h = stats['bbox']\n",
    "            color = self.colors[idx % len(self.colors)]\n",
    "            \n",
    "            # í…Œë‘ë¦¬ ì¶”ê°€\n",
    "            rect = patches.Rectangle((x, y), w, h, linewidth=4, edgecolor=color, facecolor='none')\n",
    "            axes[1].add_patch(rect)\n",
    "            \n",
    "            # í…ìŠ¤íŠ¸ ë Œë”ë§\n",
    "            for word in stats['words']:\n",
    "                total_count += 1\n",
    "                wx, wy, ww, wh = word['bbox']\n",
    "                text = word['text']\n",
    "                \n",
    "                try:\n",
    "                    axes[1].text(wx + ww/2, wy + wh/2, text,\n",
    "                               fontproperties=self.han_font,\n",
    "                               fontsize=18, color='black',\n",
    "                               verticalalignment='center', horizontalalignment='center',\n",
    "                               fontweight='bold')\n",
    "                    rendered_count += 1\n",
    "                except Exception:\n",
    "                    # í°íŠ¸ ë¬¸ì œ ì‹œ ê¸°ë³¸ ë Œë”ë§\n",
    "                    try:\n",
    "                        axes[1].text(wx + ww/2, wy + wh/2, text,\n",
    "                                   fontsize=18, color='black',\n",
    "                                   verticalalignment='center', horizontalalignment='center')\n",
    "                        rendered_count += 1\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # ì „ì²´ ì œëª©\n",
    "        avg_confidence = np.mean([stats['avg_confidence'] for stats in line_stats.values()])\n",
    "        render_rate = (rendered_count / total_count * 100) if total_count > 0 else 0\n",
    "        \n",
    "        title = f'Azure Document Intelligence OCR ì™„ì „ ë¶„ì„ ê²°ê³¼\\ní‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f} | ë Œë”ë§: {render_rate:.1f}%'\n",
    "        \n",
    "        try:\n",
    "            fig.suptitle(title, fontproperties=self.han_font, fontsize=18, y=0.95)\n",
    "        except:\n",
    "            fig.suptitle(title, fontsize=18, y=0.95)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # ì €ì¥ ë˜ëŠ” í‘œì‹œ\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"ğŸ’¾ ì‹œê°í™” ì €ì¥: {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "        # ìƒì„¸ í†µê³„ ì¶œë ¥\n",
    "        print(f\"\\nğŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(f\"   ğŸ¯ í…ìŠ¤íŠ¸ ë Œë”ë§: {rendered_count}/{total_count} ({render_rate:.1f}%)\")\n",
    "        print(f\"   ğŸ“ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
    "        print(f\"   ğŸ“„ ì„¸ë¡œì¤„ ìˆ˜: {len(vertical_lines)}\")\n",
    "        \n",
    "        for line_name, stats in line_stats.items():\n",
    "            print(f\"   {line_name}: {stats['word_count']}ê°œ ë‹¨ì–´, \"\n",
    "                  f\"ì‹ ë¢°ë„ {stats['avg_confidence']:.3f}, \"\n",
    "                  f\"í…ìŠ¤íŠ¸: {stats['full_text'][:20]}...\")\n",
    "        \n",
    "        return line_stats\n",
    "    \n",
    "    def _create_colored_boxes(self, image_path: str, vertical_lines: List[List[Dict]]) -> np.ndarray:\n",
    "        \"\"\"ìƒ‰ìƒ ë°•ìŠ¤ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            pil_image = Image.open(image_path)\n",
    "            if pil_image.mode != 'RGB':\n",
    "                pil_image = pil_image.convert('RGB')\n",
    "            \n",
    "            draw = ImageDraw.Draw(pil_image)\n",
    "            \n",
    "            color_map = {\n",
    "                'red': (255, 0, 0), 'blue': (0, 0, 255), 'green': (0, 255, 0),\n",
    "                'orange': (255, 165, 0), 'purple': (128, 0, 128), 'brown': (165, 42, 42),\n",
    "                'pink': (255, 192, 203), 'gray': (128, 128, 128), 'olive': (128, 128, 0),\n",
    "                'cyan': (0, 255, 255)\n",
    "            }\n",
    "            \n",
    "            for line_idx, line_words in enumerate(vertical_lines):\n",
    "                color_name = self.colors[line_idx % len(self.colors)]\n",
    "                color = color_map.get(color_name, (255, 0, 0))\n",
    "                \n",
    "                for word in line_words:\n",
    "                    polygon = word['polygon']\n",
    "                    points = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "                    \n",
    "                    # í…Œë‘ë¦¬\n",
    "                    draw.polygon(points, outline=color, width=3)\n",
    "                    \n",
    "                    # ë°˜íˆ¬ëª… ì±„ìš°ê¸°\n",
    "                    overlay = Image.new('RGBA', pil_image.size, (0, 0, 0, 0))\n",
    "                    overlay_draw = ImageDraw.Draw(overlay)\n",
    "                    overlay_draw.polygon(points, fill=(*color, 77))\n",
    "                    \n",
    "                    pil_image = Image.alpha_composite(pil_image.convert('RGBA'), overlay).convert('RGB')\n",
    "            \n",
    "            return np.array(pil_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ìƒ‰ìƒ ë°•ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            # ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜\n",
    "            return np.ones((300, 300, 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    def _create_line_statistics(self, vertical_lines: List[List[Dict]]) -> Dict:\n",
    "        \"\"\"ì„¸ë¡œì¤„ë³„ ìƒì„¸ í†µê³„ ìƒì„±\"\"\"\n",
    "        line_stats = {}\n",
    "        \n",
    "        for line_idx, line_words in enumerate(vertical_lines):\n",
    "            confidences = [word['confidence'] for word in line_words]\n",
    "            texts = [word['content'] for word in line_words]\n",
    "            \n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°\n",
    "            all_points = []\n",
    "            for word in line_words:\n",
    "                polygon = word['polygon']\n",
    "                points = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "                all_points.extend(points)\n",
    "            \n",
    "            if all_points:\n",
    "                min_x = min(point[0] for point in all_points)\n",
    "                max_x = max(point[0] for point in all_points)\n",
    "                min_y = min(point[1] for point in all_points)\n",
    "                max_y = max(point[1] for point in all_points)\n",
    "                \n",
    "                padding = 10\n",
    "                bbox = (\n",
    "                    int(min_x - padding),\n",
    "                    int(min_y - padding),\n",
    "                    int(max_x - min_x + 2 * padding),\n",
    "                    int(max_y - min_y + 2 * padding)\n",
    "                )\n",
    "            else:\n",
    "                bbox = (0, 0, 0, 0)\n",
    "            \n",
    "            # ê°œë³„ ë‹¨ì–´ ë°”ìš´ë”© ë°•ìŠ¤\n",
    "            word_bboxes = []\n",
    "            for word in line_words:\n",
    "                polygon = word['polygon']\n",
    "                points = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "                \n",
    "                if points:\n",
    "                    min_x = min(point[0] for point in points)\n",
    "                    max_x = max(point[0] for point in points)\n",
    "                    min_y = min(point[1] for point in points)\n",
    "                    max_y = max(point[1] for point in points)\n",
    "                    \n",
    "                    word_bboxes.append({\n",
    "                        'text': word['content'],\n",
    "                        'bbox': (int(min_x), int(min_y), int(max_x - min_x), int(max_y - min_y)),\n",
    "                        'confidence': word['confidence']\n",
    "                    })\n",
    "            \n",
    "            line_stats[f'Line {line_idx + 1}'] = {\n",
    "                'bbox': bbox,\n",
    "                'words': word_bboxes,\n",
    "                'word_count': len(line_words),\n",
    "                'avg_confidence': np.mean(confidences) if confidences else 0,\n",
    "                'full_text': ''.join(texts)\n",
    "            }\n",
    "        \n",
    "        return line_stats\n",
    "    \n",
    "    def analyze_document_complete(self, image_path: str, save_visualization: bool = True) -> Optional[Dict]:\n",
    "        \"\"\"ì™„ì „í•œ ë¬¸ì„œ ë¶„ì„ (Azure API â†’ ì‹œê°í™”)\"\"\"\n",
    "        print(f\"ğŸš€ ì™„ì „í•œ Azure OCR ë¶„ì„ ì‹œì‘\")\n",
    "        print(f\"ğŸ“„ ëŒ€ìƒ íŒŒì¼: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # 1. Azureë¡œ ì‹¤ì‹œê°„ ë¶„ì„\n",
    "        ocr_data = self.analyze_document_live(image_path)\n",
    "        \n",
    "        if not ocr_data:\n",
    "            print(\"âŒ OCR ë¶„ì„ ì‹¤íŒ¨\")\n",
    "            return None\n",
    "        \n",
    "        # 2. ì‹œê°í™” ìƒì„±\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        visualization_path = None\n",
    "        \n",
    "        if save_visualization:\n",
    "            visualization_path = f\"{Path(image_path).stem}_visualization_{timestamp}.png\"\n",
    "        \n",
    "        line_stats = self.create_dual_visualization(image_path, ocr_data, visualization_path)\n",
    "        \n",
    "        print(\"âœ… ì™„ì „í•œ ë¶„ì„ ì™„ë£Œ!\")\n",
    "        return line_stats\n",
    "\n",
    "\n",
    "def create_azure_config():\n",
    "    \"\"\"Azure ì„¤ì • íŒŒì¼ ìë™ ìƒì„± (í™˜ê²½ë³€ìˆ˜ ìš°ì„  ê¶Œì¥)\"\"\"\n",
    "    print(\"ğŸ“ Azure ì„¤ì • ë°©ë²•:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ê¶Œì¥: .env íŒŒì¼ ì‚¬ìš© (ë³´ì•ˆìƒ ì•ˆì „)\")\n",
    "    print(\"1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ ìƒì„±\")\n",
    "    print(\"2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:\")\n",
    "    print(\"   AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/\")\n",
    "    print(\"   AZURE_DOCUMENT_INTELLIGENCE_KEY=your-api-key-here\")\n",
    "    print(\"\\nëŒ€ì•ˆ: config.json íŒŒì¼ ìƒì„±\")\n",
    "    \n",
    "    config_template = {\n",
    "        \"endpoint\": \"https://your-resource-name.cognitiveservices.azure.com/\",\n",
    "        \"key\": \"your-32-character-api-key-here\",\n",
    "        \"description\": \"Azure Document Intelligence ì„¤ì • íŒŒì¼\",\n",
    "        \"created\": datetime.now().isoformat(),\n",
    "        \"instructions\": [\n",
    "            \"âš ï¸  ë³´ì•ˆìƒ .env íŒŒì¼ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\",\n",
    "            \"1. Azure Portalì—ì„œ Document Intelligence ë¦¬ì†ŒìŠ¤ ìƒì„±\",\n",
    "            \"2. í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸ ì •ë³´ë¥¼ ìœ„ í•„ë“œì— ì…ë ¥\",\n",
    "            \"3. íŒŒì¼ì„ config.jsonìœ¼ë¡œ ì €ì¥\",\n",
    "            \"4. .gitignoreì— config.json ì¶”ê°€í•˜ì—¬ ë³´ì•ˆ ìœ ì§€\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    config_path = \"config.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(config_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config_template, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"âœ… Azure ì„¤ì • í…œí”Œë¦¿ ìƒì„±: {config_path}\")\n",
    "        print(\"âš ï¸  ë³´ì•ˆì„ ìœ„í•´ .env íŒŒì¼ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤!\")\n",
    "        \n",
    "        return config_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„¤ì • íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì‹¤í–‰\"\"\"\n",
    "    print(\"ğŸš€ Azure Document Intelligence ì™„ì „ OCR ë¶„ì„ê¸°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # í™˜ê²½ë³€ìˆ˜ í™•ì¸\n",
    "    endpoint = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT')\n",
    "    key = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY')\n",
    "    \n",
    "    if not endpoint or not key:\n",
    "        print(\"âš ï¸ Azure í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ .env íŒŒì¼ì— Azure ì„¤ì •ì„ ì¶”ê°€í•˜ê±°ë‚˜ create_azure_config()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        create_azure_config()\n",
    "        return\n",
    "    \n",
    "    # OCR ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
    "    try:\n",
    "        analyzer = CompleteAzureOCRAnalyzer()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)\n",
    "    default_image_path = os.getenv('DEFAULT_IMAGE_PATH', \n",
    "                                  r\"C:\\Users\\EL76\\OneDrive\\Desktop\\IT\\Project\\5eyes-Hoyeon\\data\\raw\\training\\ì›ì²œ\\íƒœì¡°ì‹¤ë¡_001ê¶Œ_ì´ì„œ_001aë©´.jpg\")\n",
    "    \n",
    "    image_paths = [default_image_path]\n",
    "    \n",
    "    # ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "    target_image = None\n",
    "    for img_path in image_paths:\n",
    "        if os.path.exists(img_path):\n",
    "            target_image = img_path\n",
    "            break\n",
    "    \n",
    "    if target_image:\n",
    "        print(f\"\\nğŸ“„ ë¶„ì„ ëŒ€ìƒ: {target_image}\")\n",
    "        \n",
    "        # ì™„ì „í•œ ë¶„ì„ ì‹¤í–‰\n",
    "        result = analyzer.analyze_document_complete(\n",
    "            image_path=target_image,\n",
    "            save_visualization=True\n",
    "        )\n",
    "        \n",
    "        if result:\n",
    "            print(\"\\nğŸ‰ ë¶„ì„ ì„±ê³µ! ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"\\nâŒ ë¶„ì„ ì‹¤íŒ¨\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nâŒ ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"ğŸ“ ë‹¤ìŒ ê²½ë¡œì— íŒŒì¼ì„ ì¤€ë¹„í•˜ì„¸ìš”: {default_image_path}\")\n",
    "        print(\"ğŸ”§ ë˜ëŠ” DEFAULT_IMAGE_PATH í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
