{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keywords': ['조선 중기', '양반', '삶'], 'ai_eval': '전문가 평가:\\n\\n1. **키워드 반영 여부**  \\n질문에서 제시된 키워드인 ‘조선 중기’, ‘양반’, ‘삶’이 모두 충실하게 반영되어 있습니다. 답변은 조선 중기라는 시기적 범위와 양반 계층에 초점을 두고, 경제 생활, 사회적 특권, 일상/교육, 정치 참여 등 삶의 다양한 측면을 실록의 구체적 기사와 연결해 설명하고 있습니다.\\n\\n2. **사료(실록) 인용 및 출처 표기 적절성**  \\n각 항목마다 실록의 특정 기사(권, 연도, 날짜)를 명확히 표기하고 해당 기사에서 발췌한 내용(직접 인용 또는 요약)을 제시하였으므로, 사료에 근거한 설명이라는 점이 명확하게 드러납니다.  \\n예)', 'answer': '조선 중기의 양반들의 삶에 대해 조선왕조실록에 근거하여 말씀드리겠습니다.\\n\\n1. 경제 생활  \\n조선 중기 양반들은 토지를 소유하여 농민에게 소작을 주고 그 수확의 일부를 수취하는 것이 일반적이었습니다. 《중종실록》 26권, 중종 12년 9월 3일자 기사에는 \"양반들이 전답을 많이 소유하여 백성들의 형편이 곤란하다\"라는 언급이 있어, 양반의 토지 소유와 농민과의 관계가 드러납니다.\\n\\n2. 사회적 특권  \\n양반은 과거제(科擧制)를 통해 관직에 나아갈 수 있는 신분이었으며, 법적으로도 여러 특권을 누렸습니다. 《선조실록》 69권, 선조 50년 1월 10일자 기사에서는 \"양반 자제만 과거에 응시할 수 있으니, 신분에 따라 관직 진출이 제한된다\"고 기록되어 있습니다.\\n\\n3. 일상 및 교육  \\n양반 가문에서는 자제들에게 유학(儒學)을 가르치고, 효(孝)와 예(禮)를 중시하였습니다. 《광해군일기》 93권, 광해군 7년 12월 19일자 기사에는 \"양반 집안에서는 아침저녁으로 글 읽는 소리가 끊이지 않는다\"고 언급되어 있습니다.\\n\\n4. 정치 참여와 향촌 운영  \\n양반들은 지방의 향약(鄕約) 등 자치 조직을 운영하며 향촌 사회를 주도하였습니다. 《중종실록》 75권, 중종 28년 6월 13일자 기사에는 \"향약을 두어 양반들이 백성을 교화하고 다스린다\"고 나와 있습니다.\\n\\n이상은 조선왕조실록에 명시된 양반들의 삶에 관한 주요 내용입니다.'}\n"
     ]
    }
   ],
   "source": [
    "#조선왕조실록 rag\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = \"https://5team-history-azureai-services.openai.azure.com/\"\n",
    "AZURE_OPENAI_DEPLOYMENT = \"jeoson-rag\"\n",
    "AZURE_OPENAI_API_VERSION = \"2025-01-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"api.key\"\n",
    "\n",
    "# 클라이언트 생성\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "system_message = (\n",
    "    \"너는 RAG 시스템과 연동된 조선시대 한국사 전문가야. 사용자의 질문에 대해 벡터 검색된 사료 청크를 바탕으로만 답변하고, 반드시 해당 청크에서 발췌한 문장을 명시하거나 출처를 표기해야 해. 사료에 존재하지 않는 정보는 추측하지 말고 '해당 정보는 실록에서 확인되지 않습니다'라고 말해줘\"\n",
    ")\n",
    "\n",
    "def extract_keywords(query):\n",
    "    prompt = f\"다음 문장에서 핵심 키워드 3~5개만 '키워드1, 키워드2, ...' 형식으로 추출해줘:\\n{query}\\n>\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,\n",
    "        max_tokens=100,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    keywords = response.choices[0].message.content.strip()\n",
    "    return [kw.strip() for kw in keywords.split(\",\")]\n",
    "\n",
    "def evaluate_answer(keywords, answer):\n",
    "    eval_prompt = (\n",
    "        f\"다음 키워드: {', '.join(keywords)}\\n아래 답변이 키워드를 잘 반영하고 있는지 \"\n",
    "        f\"조선시대 한국사 전문가 AI 시각으로 평가해줘:\\n{answer}\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,\n",
    "        max_tokens=200,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": eval_prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def get_answer(query):\n",
    "    rag_prompt = (\n",
    "        f\"{query}\\n(다음 내용은 조선왕조실록을 참조하여 고증한 내용으로 작성되어야 합니다.)\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT,\n",
    "        max_tokens=1024,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": rag_prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"조선 중기의 양반들의 삶\"\n",
    "\n",
    "    # 1. 키워드 추출\n",
    "    keywords = extract_keywords(query)\n",
    "\n",
    "    # 2. 질문에 대한 답변 생성\n",
    "    answer = get_answer(query)\n",
    "\n",
    "    # 3. AI가 답변과 키워드 매칭 평가\n",
    "    ai_eval = evaluate_answer(keywords, answer)\n",
    "\n",
    "    # 4. JSON 결과 구성 및 출력\n",
    "    result_json = {\n",
    "        \"keywords\": keywords,\n",
    "        \"ai_eval\": ai_eval,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "    print(result_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429acbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#조선왕조실록 시놉시스rag\n",
    "import os\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "AZURE_SEARCH_ENDPOINT = \"https://5team-ai-search.search.windows.net\"\n",
    "AZURE_SEARCH_INDEX_NAME = \"rag-ksat\"\n",
    "AZURE_SEARCH_API_KEY = \"apikey\"\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = \"https://5team-history-azureai-services.openai.azure.com/\"\n",
    "AZURE_OPENAI_DEPLOYMENT = \"jeoson-rag\"\n",
    "AZURE_OPENAI_API_VERSION = \"2025-01-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"apikey\"\n",
    "\n",
    "# 클라이언트 초기화\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=AZURE_SEARCH_INDEX_NAME,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)\n",
    ")\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "def print_header(title, width=80):\n",
    "    \"\"\"헤더 출력\"\"\"\n",
    "    print(\"\\n\" + \"=\"*width)\n",
    "    print(f\"🎯 {title}\")\n",
    "    print(\"=\"*width)\n",
    "\n",
    "def print_section(title, width=60):\n",
    "    \"\"\"섹션 출력\"\"\"\n",
    "    print(f\"\\n{'='*10} {title} {'='*10}\")\n",
    "\n",
    "def print_subsection(title):\n",
    "    \"\"\"하위 섹션 출력\"\"\"\n",
    "    print(f\"\\n📌 {title}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def extract_keywords_from_query(query, top_k=10, max_final_docs=10):\n",
    "    \"\"\"\n",
    "    AI를 이용해 쿼리에서 검색 키워드 자동 추출\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 입력 쿼리\n",
    "        top_k (int): 키워드당 검색할 문서 수\n",
    "        max_final_docs (int): 최종 선별할 문서 수\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (추출된 키워드 리스트, 키워드 추출 상세 정보)\n",
    "    \"\"\"\n",
    "    print_subsection(\"AI 기반 키워드 자동 추출\")\n",
    "    print(f\"🔍 입력 쿼리: {query}\")\n",
    "    \n",
    "    keyword_extraction_prompt = f\"\"\"\n",
    "사용자 쿼리: \"{query}\"\n",
    "\n",
    "위 쿼리를 분석하여 Azure Search에서 관련 문서를 찾기 위한 최적의 검색 키워드들을 추출해주세요.\n",
    "\n",
    "추출 기준:\n",
    "1. 쿼리의 핵심 주제와 관련된 키워드\n",
    "2. 역사적 인물명, 사건명, 제도명\n",
    "3. 시대적 배경 키워드  \n",
    "4. 관련 개념어 및 전문용어\n",
    "5. 유사한 의미의 동의어들\n",
    "6. 검색에 유용한 단일어 우선 (2-3글자 단어들)\n",
    "\n",
    "응답 형식:\n",
    "핵심키워드: [가장 중요한 키워드 5개를 콤마로 구분]\n",
    "확장키워드: [관련된 추가 키워드 10개를 콤마로 구분] \n",
    "동의어키워드: [동의어나 유사어 5개를 콤마로 구분]\n",
    "인물키워드: [관련 인물명 5개를 콤마로 구분 - 있다면]\n",
    "시대키워드: [시대/왕조 관련 3개를 콤마로 구분 - 있다면]\n",
    "\n",
    "추출 이유: [키워드 선택 이유를 2-3줄로 설명]\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"🤖 AI 키워드 추출 중...\")\n",
    "        \n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT,\n",
    "            max_tokens=800,\n",
    "            temperature=0.3,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"한국사 전문가이자 검색 키워드 추출 전문가입니다. 사용자 쿼리에서 문서 검색에 가장 효과적인 키워드들을 추출합니다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": keyword_extraction_prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        extraction_result = response.choices[0].message.content.strip()\n",
    "        print(\"✅ AI 키워드 추출 완료\")\n",
    "        \n",
    "        # 키워드 파싱\n",
    "        keywords = []\n",
    "        extraction_info = {\n",
    "            'core': [],\n",
    "            'extended': [], \n",
    "            'synonyms': [],\n",
    "            'persons': [],\n",
    "            'periods': [],\n",
    "            'reasoning': ''\n",
    "        }\n",
    "        \n",
    "        lines = extraction_result.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('핵심키워드:'):\n",
    "                core_kw = line.replace('핵심키워드:', '').strip()\n",
    "                extraction_info['core'] = [kw.strip() for kw in core_kw.split(',') if kw.strip()]\n",
    "                keywords.extend(extraction_info['core'])\n",
    "                \n",
    "            elif line.startswith('확장키워드:'):\n",
    "                ext_kw = line.replace('확장키워드:', '').strip()\n",
    "                extraction_info['extended'] = [kw.strip() for kw in ext_kw.split(',') if kw.strip()]\n",
    "                keywords.extend(extraction_info['extended'])\n",
    "                \n",
    "            elif line.startswith('동의어키워드:'):\n",
    "                syn_kw = line.replace('동의어키워드:', '').strip()\n",
    "                extraction_info['synonyms'] = [kw.strip() for kw in syn_kw.split(',') if kw.strip()]\n",
    "                keywords.extend(extraction_info['synonyms'])\n",
    "                \n",
    "            elif line.startswith('인물키워드:'):\n",
    "                person_kw = line.replace('인물키워드:', '').strip()\n",
    "                extraction_info['persons'] = [kw.strip() for kw in person_kw.split(',') if kw.strip()]\n",
    "                keywords.extend(extraction_info['persons'])\n",
    "                \n",
    "            elif line.startswith('시대키워드:'):\n",
    "                period_kw = line.replace('시대키워드:', '').strip()\n",
    "                extraction_info['periods'] = [kw.strip() for kw in period_kw.split(',') if kw.strip()]\n",
    "                keywords.extend(extraction_info['periods'])\n",
    "                \n",
    "            elif line.startswith('추출 이유:'):\n",
    "                extraction_info['reasoning'] = line.replace('추출 이유:', '').strip()\n",
    "        \n",
    "        # 중복 제거 및 정리\n",
    "        unique_keywords = []\n",
    "        seen = set()\n",
    "        for kw in keywords:\n",
    "            if kw and kw not in seen and len(kw.strip()) >= 2:\n",
    "                unique_keywords.append(kw.strip())\n",
    "                seen.add(kw)\n",
    "        \n",
    "        print(f\"📊 추출된 키워드 통계:\")\n",
    "        print(f\"   - 핵심키워드: {len(extraction_info['core'])}개\")\n",
    "        print(f\"   - 확장키워드: {len(extraction_info['extended'])}개\") \n",
    "        print(f\"   - 동의어키워드: {len(extraction_info['synonyms'])}개\")\n",
    "        print(f\"   - 인물키워드: {len(extraction_info['persons'])}개\")\n",
    "        print(f\"   - 시대키워드: {len(extraction_info['periods'])}개\")\n",
    "        print(f\"   - 총 유효 키워드: {len(unique_keywords)}개\")\n",
    "        \n",
    "        print(f\"\\n🔑 최종 키워드 목록:\")\n",
    "        for i, kw in enumerate(unique_keywords[:20], 1):  # 상위 20개만 출력\n",
    "            print(f\"   {i:2d}. {kw}\")\n",
    "        \n",
    "        if len(unique_keywords) > 20:\n",
    "            print(f\"   ... 외 {len(unique_keywords) - 20}개\")\n",
    "            \n",
    "        print(f\"\\n💡 추출 이유: {extraction_info['reasoning']}\")\n",
    "        \n",
    "        return unique_keywords, extraction_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 키워드 추출 오류: {e}\")\n",
    "        # 실패 시 쿼리에서 간단한 키워드 추출\n",
    "        fallback_keywords = []\n",
    "        # 한글 2글자 이상 단어 추출\n",
    "        korean_words = re.findall(r'[가-힣]{2,}', query)\n",
    "        fallback_keywords.extend(korean_words[:10])\n",
    "        \n",
    "        print(f\"🔄 대안 키워드 사용: {fallback_keywords}\")\n",
    "        return fallback_keywords, {'reasoning': '자동 추출 실패로 쿼리 단어 사용'}\n",
    "\n",
    "def search_documents_with_keywords(keywords, top_k=10, max_final_docs=10):\n",
    "    \"\"\"\n",
    "    추출된 키워드로 문서 검색\n",
    "    \n",
    "    Args:\n",
    "        keywords (list): 검색 키워드 리스트\n",
    "        top_k (int): 키워드당 검색할 문서 수  \n",
    "        max_final_docs (int): 최종 선별할 문서 수\n",
    "        \n",
    "    Returns:\n",
    "        list: 검색된 관련 문서들\n",
    "    \"\"\"\n",
    "    print_subsection(f\"키워드 기반 문서 검색\")\n",
    "    print(f\"🔍 검색 키워드: {len(keywords)}개\")\n",
    "    print(f\"📊 검색 설정: 키워드당 {top_k}개, 최종 {max_final_docs}개\")\n",
    "    \n",
    "    all_docs = []\n",
    "    search_stats = {\"total_searched\": 0, \"found_docs\": 0, \"total_results\": 0}\n",
    "    \n",
    "    print(f\"\\n{'키워드':<15} | {'검색결과':<8} | {'관련문서':<8} | {'최고점수':<10} | {'상태'}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            results = search_client.search(\n",
    "                search_text=keyword,\n",
    "                top=top_k,\n",
    "                search_mode=\"any\"\n",
    "            )\n",
    "            \n",
    "            search_stats[\"total_searched\"] += 1\n",
    "            found_count = 0\n",
    "            max_score = 0\n",
    "            \n",
    "            for result in results:\n",
    "                chunk = result.get('chunk', '')\n",
    "                score = result.get('@search.score', 0)\n",
    "                search_stats[\"total_results\"] += 1\n",
    "                max_score = max(max_score, score)\n",
    "                \n",
    "                if chunk and len(chunk.strip()) > 50:  # 의미있는 내용만\n",
    "                    clean_preview = ' '.join(chunk.replace('\\n', ' ').split())\n",
    "                    preview_text = clean_preview[:100] + \"...\" if len(clean_preview) > 100 else clean_preview\n",
    "                    \n",
    "                    all_docs.append({\n",
    "                        'keyword': keyword,\n",
    "                        'chunk': chunk,\n",
    "                        'score': score,\n",
    "                        'preview': preview_text\n",
    "                    })\n",
    "                    found_count += 1\n",
    "            \n",
    "            if found_count > 0:\n",
    "                search_stats[\"found_docs\"] += 1\n",
    "                status = \"✅ 발견\"\n",
    "            else:\n",
    "                status = \"❌ 없음\"\n",
    "                \n",
    "            print(f\"{keyword:<15} | {search_stats['total_results']:>8} | {found_count:>8} | {max_score:>10.2f} | {status}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"{keyword:<15} | {'오류':>8} | {'0':>8} | {'0.00':>10} | ⚠️ 실패\")\n",
    "    \n",
    "    print_subsection(\"검색 통계\")\n",
    "    print(f\"📊 총 검색 키워드: {search_stats['total_searched']}개\")\n",
    "    print(f\"📊 총 검색된 문서: {search_stats['total_results']}개\")\n",
    "    print(f\"📊 유효 문서: {len(all_docs)}개\")\n",
    "    print(f\"📊 키워드 성공률: {(search_stats['found_docs']/max(search_stats['total_searched'], 1)*100):.1f}%\")\n",
    "    \n",
    "    # 점수 기준 정렬 및 중복 제거\n",
    "    all_docs.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    unique_docs = []\n",
    "    seen_previews = set()\n",
    "    \n",
    "    for doc in all_docs:\n",
    "        # 문서 내용으로 중복 체크 (앞의 200자)\n",
    "        content_key = ' '.join(doc['chunk'][:200].replace('\\n', ' ').split())\n",
    "        if content_key not in seen_previews:\n",
    "            unique_docs.append(doc)\n",
    "            seen_previews.add(content_key)\n",
    "            if len(unique_docs) >= max_final_docs:\n",
    "                break\n",
    "    \n",
    "    print_subsection(f\"최종 선별 문서 ({len(unique_docs)}개)\")\n",
    "    print(f\"{'순위':<4} | {'키워드':<12} | {'검색점수':<10} | {'미리보기'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, doc in enumerate(unique_docs, 1):\n",
    "        clean_preview = ' '.join(doc['preview'].replace('\\n', ' ').split())[:50]\n",
    "        print(f\"{i:<4} | {doc['keyword']:<12} | {doc['score']:>10.2f} | {clean_preview}...\")\n",
    "    \n",
    "    return unique_docs\n",
    "\n",
    "def find_documents_from_query(query, top_k=10, max_final_docs=10):\n",
    "    \"\"\"\n",
    "    쿼리에서 키워드를 자동 추출하고 문서 검색하는 통합 함수\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 입력 쿼리\n",
    "        top_k (int): 키워드당 검색할 문서 수\n",
    "        max_final_docs (int): 최종 선별할 문서 수\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (검색된 문서들, 키워드 정보)\n",
    "    \"\"\"\n",
    "    print_header(\"쿼리 기반 자동 문서 검색 시스템\")\n",
    "    print(f\"📝 입력 쿼리: {query}\")\n",
    "    print(f\"⏰ 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 1단계: AI 키워드 추출\n",
    "    print_section(\"1️⃣ AI 키워드 추출\")\n",
    "    keywords, keyword_info = extract_keywords_from_query(query, top_k, max_final_docs)\n",
    "    \n",
    "    if not keywords:\n",
    "        print(\"❌ 키워드 추출에 실패했습니다.\")\n",
    "        return [], {}\n",
    "    \n",
    "    # 2단계: 키워드로 문서 검색\n",
    "    print_section(\"2️⃣ 키워드 기반 문서 검색\")\n",
    "    documents = search_documents_with_keywords(keywords, top_k, max_final_docs)\n",
    "    \n",
    "    return documents, keyword_info\n",
    "\n",
    "def create_context_from_best_docs(docs):\n",
    "    \"\"\"문서에서 컨텍스트 생성\"\"\"\n",
    "    if not docs:\n",
    "        return \"관련 문서를 찾을 수 없습니다.\"\n",
    "    \n",
    "    print_subsection(\"컨텍스트 생성\")\n",
    "    \n",
    "    context_parts = []\n",
    "    total_length = 0\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        doc_content = f\"=== 참고문서 {i} (키워드: {doc['keyword']}, 점수: {doc['score']:.2f}) ===\\n{doc['chunk']}\"\n",
    "        context_parts.append(doc_content)\n",
    "        total_length += len(doc['chunk'])\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    print(f\"📄 총 문서 수: {len(docs)}개\")\n",
    "    print(f\"📄 총 컨텍스트 길이: {len(context):,}자\")\n",
    "    print(f\"📄 평균 문서 길이: {total_length//len(docs):,}자\")\n",
    "    \n",
    "    return context\n",
    "\n",
    "def smart_synopsis_generation(query, context):\n",
    "    \"\"\"스마트 시놉시스 생성\"\"\"\n",
    "    print_subsection(\"AI 기반 내용 분석\")\n",
    "    \n",
    "    # 1단계: 관련성 평가\n",
    "    print(\"🔍 1단계: 자료 관련성 평가 중...\")\n",
    "    relevance_check_prompt = f\"\"\"\n",
    "질문: {query}\n",
    "제공된 자료: {context[:1500]}...\n",
    "\n",
    "이 자료가 질문과 얼마나 관련이 있는지 1-10점으로 평가하고, \n",
    "주요 관련 내용을 3-5개 불릿포인트로 요약해주세요.\n",
    "\n",
    "평가 형식:\n",
    "점수: X/10\n",
    "주요 내용:\n",
    "- 내용1\n",
    "- 내용2\n",
    "- 내용3\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        relevance_response = openai_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT,\n",
    "            max_tokens=400,\n",
    "            temperature=0.1,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"자료 관련성 평가 전문가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": relevance_check_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        relevance_info = relevance_response.choices[0].message.content.strip()\n",
    "        print(\"✅ 관련성 평가 완료\")\n",
    "        \n",
    "        # 점수 추출\n",
    "        relevance_score = \"정보없음\"\n",
    "        for line in relevance_info.split('\\n'):\n",
    "            if '점수:' in line:\n",
    "                relevance_score = line.replace('점수:', '').strip()\n",
    "                break\n",
    "        \n",
    "        print(f\"📊 관련성 점수: {relevance_score}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 관련성 평가 오류: {e}\")\n",
    "        relevance_info = \"평가 실패\"\n",
    "        relevance_score = \"오류\"\n",
    "    \n",
    "    # 2단계: 시놉시스 생성\n",
    "    print(\"\\n📝 2단계: 시놉시스 생성 중...\")\n",
    "    synopsis_prompt = f\"\"\"\n",
    "질문: {query}\n",
    "\n",
    "관련성 평가: {relevance_info}\n",
    "\n",
    "참고 자료:\n",
    "{context}\n",
    "\n",
    "위 자료를 바탕으로 웹툰/드라마 스타일의 흥미진진한 시놉시스를 작성해주세요!\n",
    "\n",
    "스타일 요구사항:\n",
    "1. 400-500자 분량\n",
    "2. 웹툰이나 사극 드라마처럼 흥미진진하고 역동적으로 작성\n",
    "3. \"~다!\", \"~었다!\", \"하지만!\", \"그런데!\" 같은 감탄부호 적극 활용\n",
    "4. 인물들의 감정과 갈등을 생생하게 묘사\n",
    "5. 긴장감과 반전이 있는 스토리텔링\n",
    "6. 독자가 \"다음이 궁금해!\"라고 느낄 수 있게 작성\n",
    "7. 구체적인 인물명과 사건을 포함하되 드라마틱하게 각색\n",
    "\n",
    "예시 톤:\n",
    "\"왕좌를 둘러싼 치열한 권력투쟁이 시작된다! 영조는 외쳤다 - '이 나라에 붕당은 필요 없다!' 하지만 신하들의 속마음은 달랐다...\"\n",
    "\n",
    "시놉시스:\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        synopsis_response = openai_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT,\n",
    "            max_tokens=1000,\n",
    "            temperature=1.0,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"역사와 이야기를 생생하고 몰입감 있게 전달하는 한국사 교육 전문가입니다.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": synopsis_prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        synopsis = synopsis_response.choices[0].message.content.strip()\n",
    "        print(\"✅ 시놉시스 생성 완료\")\n",
    "        print(f\"📊 생성된 시놉시스 길이: {len(synopsis)}자\")\n",
    "        \n",
    "        return synopsis, relevance_info, relevance_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 시놉시스 생성 오류: {e}\")\n",
    "        return \"시놉시스 생성에 실패했습니다.\", relevance_info, relevance_score\n",
    "\n",
    "def final_evaluation(synopsis, query):\n",
    "    \"\"\"최종 평가\"\"\"\n",
    "    print_subsection(\"품질 평가\")\n",
    "    print(\"🔍 AI 품질 평가 진행 중...\")\n",
    "    \n",
    "    eval_prompt = f\"\"\"\n",
    "질문: {query}\n",
    "작성된 시놉시스: {synopsis}\n",
    "\n",
    "다음 기준으로 평가해주세요:\n",
    "\n",
    "1. 질문 적합성 (1-5점): 질문의 핵심을 얼마나 잘 다뤘는가?\n",
    "2. 내용 구체성 (1-5점): 구체적인 사실과 예시가 포함되었는가?\n",
    "3. 교육적 가치 (1-5점): 학습에 도움이 되는가?\n",
    "4. 완성도 (1-5점): 전체적으로 완성도가 높은가?\n",
    "\n",
    "평가 형식:\n",
    "1. 질문 적합성: X/5점 - 설명\n",
    "2. 내용 구체성: X/5점 - 설명  \n",
    "3. 교육적 가치: X/5점 - 설명\n",
    "4. 완성도: X/5점 - 설명\n",
    "\n",
    "총점: XX/20점\n",
    "\n",
    "장점:\n",
    "- 장점1\n",
    "- 장점2\n",
    "\n",
    "개선점:\n",
    "- 개선점1\n",
    "- 개선점2\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        eval_response = openai_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT,\n",
    "            max_tokens=600,\n",
    "            temperature=0.5,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"교육 콘텐츠 평가 전문가입니다.\"},\n",
    "                {\"role\": \"user\", \"content\": eval_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        evaluation = eval_response.choices[0].message.content.strip()\n",
    "        print(\"✅ 품질 평가 완료\")\n",
    "        \n",
    "        # 총점 추출\n",
    "        total_score = \"정보없음\"\n",
    "        for line in evaluation.split('\\n'):\n",
    "            if '총점:' in line:\n",
    "                total_score = line.replace('총점:', '').strip()\n",
    "                break\n",
    "        \n",
    "        print(f\"📊 최종 점수: {total_score}\")\n",
    "        \n",
    "        return evaluation, total_score\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 품질 평가 오류: {e}\")\n",
    "        return \"평가에 실패했습니다.\", \"오류\"\n",
    "\n",
    "def display_final_results(result):\n",
    "    \"\"\"최종 결과 출력\"\"\"\n",
    "    print_header(\"최종 분석 결과\", width=100)\n",
    "    \n",
    "    # 기본 정보\n",
    "    print_subsection(\"🎯 분석 개요\")\n",
    "    print(f\"📝 분석 질의: {result['query']}\")\n",
    "    print(f\"⏰ 분석 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📊 추출된 키워드: {len(result.get('keywords', []))}개\")\n",
    "    print(f\"📊 사용된 문서: {len(result['relevant_docs'])}개\")\n",
    "    print(f\"📊 관련성 점수: {result.get('relevance_score', '정보없음')}\")\n",
    "    print(f\"📊 최종 품질 점수: {result.get('total_score', '정보없음')}\")\n",
    "    \n",
    "    # 키워드 정보\n",
    "    if result.get('keyword_info'):\n",
    "        print_subsection(\"🔑 추출된 키워드 정보\")\n",
    "        kw_info = result['keyword_info']\n",
    "        if kw_info.get('core'):\n",
    "            print(f\"핵심키워드: {', '.join(kw_info['core'][:5])}\")\n",
    "        if kw_info.get('extended'):\n",
    "            print(f\"확장키워드: {', '.join(kw_info['extended'][:5])}\")\n",
    "        if kw_info.get('persons'):\n",
    "            print(f\"인물키워드: {', '.join(kw_info['persons'][:3])}\")\n",
    "    \n",
    "    # 검색된 문서 요약\n",
    "    print_subsection(\"📚 주요 발견 문서\")\n",
    "    for i, doc in enumerate(result['relevant_docs'][:3], 1):\n",
    "        clean_content = ' '.join(doc['preview'].replace('\\n', ' ').split())\n",
    "        print(f\"{i}. 키워드: [{doc['keyword']}] | 검색점수: {doc['score']:.2f}\")\n",
    "        print(f\"   📄 내용: {clean_content}\")\n",
    "        print()\n",
    "    \n",
    "    # 생성된 시놉시스\n",
    "    print_subsection(\"📖 생성된 시놉시스\")\n",
    "    print(\"╔\" + \"═\" * 78 + \"╗\")\n",
    "    synopsis_lines = result['synopsis'].split('\\n')\n",
    "    for line in synopsis_lines:\n",
    "        if len(line) > 76:\n",
    "            words = line.split(' ')\n",
    "            current_line = \"\"\n",
    "            for word in words:\n",
    "                if len(current_line + word) <= 76:\n",
    "                    current_line += word + \" \"\n",
    "                else:\n",
    "                    print(f\"║ {current_line.ljust(76)} ║\")\n",
    "                    current_line = word + \" \"\n",
    "            if current_line.strip():\n",
    "                print(f\"║ {current_line.strip().ljust(76)} ║\")\n",
    "        else:\n",
    "            print(f\"║ {line.ljust(76)} ║\")\n",
    "    print(\"╚\" + \"═\" * 78 + \"╝\")\n",
    "    \n",
    "    # 품질 평가\n",
    "    print_subsection(\"📊 품질 평가 결과\")\n",
    "    eval_lines = result['evaluation'].split('\\n')\n",
    "    for line in eval_lines:\n",
    "        if line.strip():\n",
    "            if any(keyword in line for keyword in ['질문 적합성', '내용 구체성', '교육적 가치', '완성도']):\n",
    "                print(f\"  📈 {line}\")\n",
    "            elif '총점:' in line:\n",
    "                print(f\"  🎯 {line}\")\n",
    "            elif line.startswith('장점:') or line.startswith('개선점:'):\n",
    "                print(f\"  📌 {line}\")\n",
    "            elif line.startswith('- '):\n",
    "                print(f\"    {line}\")\n",
    "            else:\n",
    "                print(f\"  {line}\")\n",
    "\n",
    "def ultimate_rag_solution(query, top_k=10, max_final_docs=10):\n",
    "    \"\"\"\n",
    "    쿼리 기반 자동 RAG 시스템 - AI가 키워드를 자동 추출\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 입력 쿼리 (어떤 주제든 가능)\n",
    "        top_k (int): 키워드당 검색할 문서 수\n",
    "        max_final_docs (int): 최종 선별할 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        dict: 분석 결과\n",
    "    \"\"\"\n",
    "    print_header(f\"AI 자동 키워드 추출 RAG 시스템\", width=100)\n",
    "    print(f\"🚀 시스템 시작: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📝 분석 주제: {query}\")\n",
    "    print(f\"🎯 검색 설정: 키워드당 {top_k}개, 최종 {max_final_docs}개 문서\")\n",
    "    \n",
    "    # 1단계: AI 키워드 추출 및 문서 검색\n",
    "    print_section(\"1️⃣ AI 키워드 추출 및 문서 검색\")\n",
    "    relevant_docs, keyword_info = find_documents_from_query(query, top_k, max_final_docs)\n",
    "    \n",
    "    if not relevant_docs:\n",
    "        print(\"❌ 관련 문서를 찾을 수 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 추출된 키워드 정보\n",
    "    keywords = []\n",
    "    if keyword_info:\n",
    "        keywords.extend(keyword_info.get('core', []))\n",
    "        keywords.extend(keyword_info.get('extended', []))\n",
    "        keywords.extend(keyword_info.get('persons', []))\n",
    "    \n",
    "    # 2단계: 컨텍스트 생성\n",
    "    print_section(\"2️⃣ 컨텍스트 생성 단계\")\n",
    "    context = create_context_from_best_docs(relevant_docs)\n",
    "    \n",
    "    # 3단계: 시놉시스 생성\n",
    "    print_section(\"3️⃣ 시놉시스 생성 단계\")\n",
    "    synopsis, relevance_info, relevance_score = smart_synopsis_generation(query, context)\n",
    "    \n",
    "    # 4단계: 품질 평가\n",
    "    print_section(\"4️⃣ 품질 평가 단계\")\n",
    "    evaluation, total_score = final_evaluation(synopsis, query)\n",
    "    \n",
    "    # 결과 정리\n",
    "    result = {\n",
    "        'query': query,\n",
    "        'keywords': keywords,\n",
    "        'keyword_info': keyword_info,\n",
    "        'search_settings': {\n",
    "            'top_k': top_k,\n",
    "            'max_final_docs': max_final_docs\n",
    "        },\n",
    "        'relevant_docs': relevant_docs,\n",
    "        'context': context,\n",
    "        'synopsis': synopsis,\n",
    "        'relevance_info': relevance_info,\n",
    "        'relevance_score': relevance_score,\n",
    "        'evaluation': evaluation,\n",
    "        'total_score': total_score,\n",
    "        'timestamp': datetime.now()\n",
    "    }\n",
    "    \n",
    "    # 5단계: 최종 결과 출력\n",
    "    print_section(\"5️⃣ 최종 결과\")\n",
    "    display_final_results(result)\n",
    "    \n",
    "    print_header(\"분석 완료\", width=100)\n",
    "    print(f\"🏁 분석 종료: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"조선시대 왕과 신하 갈등\"\n",
    "    result = ultimate_rag_solution(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
